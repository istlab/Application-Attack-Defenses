\documentclass[conference]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
%\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{color}
\usepackage{url}
%\usepackage{moreverb}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{mathptmx}
\usepackage{dingbat}
\usepackage{pifont}
\usepackage{acronym}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{supertabular}
\usepackage{listings}
\usepackage{threeparttable}
\usepackage{pdflscape}
\usepackage{array}
\usepackage{multirow}
\usepackage{subfigure}

\usepackage[numbers,sort]{natbib}
\lstset{columns=flexible,showstringspaces=false}

\renewcommand{\algorithmiccomment}[1]{\hfill {\tt //} #1}
\newcommand{\tick}{\ding{52}}
\newcommand{\xmark}{\ding{56}}

\date{}
\begin{document}

\author{
\IEEEauthorblockN{Dimitris Mitropoulos,\IEEEauthorrefmark{1}
Panos Louridas,\IEEEauthorrefmark{2},
Michalis Polychronakis,\IEEEauthorrefmark{1}
and Angelos Keromytis\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}
Network Security Lab\\
Department of Computer Scinence\\
Columbia University\\
\{dimitro, mikepo, angelos\}@cs.columbia.edu\\
\IEEEauthorrefmark{2}
Software Engineering and Security Lab\\
Department of Management Science and Technology\\
Athens University of Economics and Business\\
louridas@aueb.gr
}}

\title{SoK: The Evolution of Defenses Against Web Application Attacks}

\maketitle
\begin{abstract}

  Some of the most dangerous web application attacks, like Cross-Site
  Scripting and {\sc sql} injection, exploit the oversight of
  programmers that develop applications which may accept and process
  data of uncertain origin without appropriate validation and / or
  filtering. Such attacks, relying on source code injection
  vulnerabilities, have been constantly topping the lists of the
  various security bulletin providers despite the numerous
  countermeasures that have been proposed over the past 15 years.

  In this paper we systematize the existing knowledge regarding
  various defense mechanisms against source code injection by setting
  up a model that highlights the key weaknesses behind such attacks and
  helps us observe defenses from a common perspective.

  We then categorize and analyze the various defense mechanisms that
  have been developed. Our analysis is based on dimensions such as
  accuracy, performance, deployment and security. Especially notable
  for a key category is accuracy, as our findings show that there are
  many defense mechanisms that are tested in a poor manner.

  By comparing the existing defenses and identifying their common
  characteristics, we help: a) researchers and practitioners to choose
  or modify a mechanism according to their needs, and b) designers of
  new approaches in developing more efficient mechanisms.
% @dimitro: change the above accordingly.


%In this paper we examine how application attack defense
%mechanism are developed and presented to
%the research community.
\end{abstract}

\begin{IEEEkeywords}
Security and Protection, Application Security, Code injection Attacks.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction Remarks}

Web application attacks may involve security misconfigurations,
broken authentication and session management, or other issues.
Some of the most dangerous web application attacks, though,
are associated with the processing of external input data
that may contain malicious code, a vulnerability known as
code injection.

Such attacks include Cross-Site Scripting ({\sc xss})
attacks~\cite{SG07}, {\sc sql} injection attacks~\cite{RL12b},
Cross-Site Request Forgery ({\sc csrf}) attacks~\cite{LZRL09}, and
others. Attacks like these have been topping the vulnerability lists
of numerous bulletin providers like the Open Web Application Security
Project\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}
({\sc owasp}) and
{\sc mitre}\footnote{\url{http://cwe.mitre.org/top25/}} for several
years. Consider the case of {\sc owasp}'s Top Ten project whose main
goal is to raise awareness about web application security by
identifying some of the most critical risks facing organizations which
is referenced by numerous researchers. In its three consecutive Top
Ten lists (2007, 2010, 2013), different executable source code-driven
injection attacks dominate the top five positions. Malicious users
find new ways to bypass defense mechanisms by using a variety of
techniques despite the numerous countermeasures that are being
introduced. Note that the number of systems developed to counter
{\sc sql} injection attacks until 2006 was more than twenty~\cite{HVO06}.
Since then the number has doubled.
Researchers have also indicated that the number of such attacks
is steadily increasing in recent years~\cite{SSL12}.

There is already a survey on mitigating
software vulnerabilities in general~\cite{SZ12}.
The scope of that research is pretty wide and leaves
out many approaches and mechanisms that we report here.
This is mainly because this work includes countermeasures
that detect such vulnerabilities via program analysis
(which is done during development or testing), while
we include protection mechanisms that counter
such attacks when they take place.
Also, countermeasures that prevent {\sc sql}
injection attacks~\cite{HVO06}, have already been surveyed.
However, this survey is quite old and since then
the number of countermeasures that detect {\sc sql}
injection attacks alone, has been drastically increased
as we mentioned in the previous paragraph.

In our research we focus on the top
{\sc tba} systems that and are presented
in publications cited more than twenty times.
For the sake of our study, we choose
to make some exceptions and include some latest mechanisms
that were presented in top security conferences even if
the corresponding publications have been cited less than
twenty times.

% TODO@dimitro: explain why you leave out {\it SecuriFly}~\cite{MLL05}.

Introduction~\cite{I05}. Also see~\cite{A00}.

Requirements:
\begin{itemize}
\item {\it Diagnostic Performance} As long
as we examine protection mechanisms that detect
attacks, the non-existence of false positive and
negative alarms is a reasonable requirement.
\item {\it Computational Performance} We examine
the overhead of the mechanisms
that affect the experience of a web user who actually
uses the protected application.
\item {\it Ease of use} We examine if the protection
mechanism is practical in terms of deployment
and can be easily adopted by security experts.
\item {\it Security} How resilient is the system to
attackers that know how it works and wants to circumvent it.
\item {\it Detection Locus}
\item {\it Availability}
\end{itemize}

All the aforementioned requirements are considered critical
when building security mechanisms that protect
applications~\cite{A01,A00}.

\section{Attacks}
\label{sec:attacks}

The basic problem behind the most dangerous
web application attacks involves
the absence of input validation. By taking advantage of
this, attackers can inject their code into
applications to perform malicious tasks. Such
an exploit can have different forms depending on the
execution context of the application and the location
of the programming flaw that leads to the attack.

Bratus et al.~\cite{BLSPS11} portray the issue in a generic fashion:
{\it ``unexpected (and unexpectedly powerful) computational models
inside targeted systems, which turn a part of the target into a
so-called `weird machine' programmable by the attacker via crafted inputs
(a.k.a. `exploits')''}.
An example of the above definition is the
following: The code fragment below defines the operation of
addition in the Scheme programming language~\cite{AS96,D09}:

\begin{verbatim}
(define (add x y) (+ x y))
\end{verbatim}

\noindent
Consider the case where instead of a number, a function that leads to an
endless loop is passed as an argument by the user. This will cause
the interpreter to enter
an endless loop and lead to a denial of service.
% Keep in mind that a {\sc cia} does not require a programming
% language with first-class functions.
The intuition here is that {\it ``every application that copies
untrusted input verbatim into an output
program is vulnerable to code injection''}.
Ray and Ligatti~\cite{RL12b} actually proved the above
claim based on formal language theory.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[scale=0.47]{attack-tree-uml.pdf}
\end{center}
\caption{\label{fig:taxonomy}A taxonomy of executable source
code injection attacks.}
\end{figure}

Code injection attacks can be divided into two categories. The first
involves binary code and the second executable source code. An
extensive survey on binary code injection attacks can be found
in~\cite{LC03}. Specific advances in exploiting such vulnerabilities
(i.e. ``heap smashing", ``arc injection" and others) have been
presented in~\cite{PB04}. The countermeasures used to detect such
defects have already been surveyed~\cite{YJP12} (many of them are also
included in a book:~\cite{DKZ12} -- Section 13.8). In the present work
we do not include binary code injection, focusing instead on defenses
that protect applications against application attacks based on the
executable source code injection category.

\subsection{Executable Source Code Injection Vulnerabilities}

Figure~\ref{fig:taxonomy} presents a taxonomy of executable source
code injection attacks. Such attacks may involve source code, either of a
{\it Domain Specific Language} ({\sc dsl}) or a {\it Dynamic Language}.

Application attacks that involve {\sc dsl}s constitute an important
subset of the code injection problem, as {\sc dsl}s like {\sc sql} and
{\sc xml} play an significant role in the development of either web or
mobile applications. For example, many applications have interfaces
where a user enters input to interact with the application's data,
thereby interacting with the underlying Relational Database Management
System ({\sc rdbms}). This input can become part of an {\sc sql} query
and executed on the target {\sc rdbms}. A code injection attack that
exploits the vulnerabilities of these interfaces by taking advantage
of input validation issues like incorrectly passed parameters or
incorrect type handling, is called an {\sc sql} injection
attack~\cite{CERT02,MS09,HVO06,SW06}. By using similar techniques
malicious users can perform other exploits based on {\sc dsl}s,
like {\sc xp}ath~\cite{SW06,CDL07,MKS09}, {\sc xml}~\cite{MSM13}
and No{\sc sql}~\cite{SMS13}. With this kind of attacks,
a malicious user can view sensitive information,
destroy or modify protected data, or even crash the entire
application. {\sc html} is another {\sc dsl} that can be used
for malicious purposes when an application does not properly
handle user supplied data. Based on this vulnerability
an attacker can supply valid {\sc html},
typically via a parameter value, and inject their own
content into the page. {\sc html} injection is mainly associated
with {\sc xss} defects.

A recent class of {\sc cia}s involve dynamic languages like
JavaScript and {\sc php}~\cite{SFVM09,EWKK09,SMS13}. JavaScript
injection attacks, in particular, make up a large subset of dynamic
language-driven attacks. Such attacks are manifested when a web
application accepts and redisplays data of uncertain origin without
appropriate validation and filtering. Based on this flaw, an attacker
can manage to inject a script in the JavaScript engine of a browser
and alter its execution flow~\cite{ELX07}. JavaScript injection
attacks are considered as a critical issue in web application security
mainly because they are associated with major vulnerabilities such as:
{\sc xss} attacks~\cite{SG07}, {\sc csrf} attacks~\cite{BJM08,LZRL09} and
Cross-Channel Scripting ({\sc xcs}) attacks~\cite{W10,BBB09}.
In many cases {\sc xss} attacks involve the injection of
both {\sc html} and JavaScript code.

% {\sc html} injection --- such attacks pose no threat to cookies and session IDs.

\subsection{Exploitation Model}
\label{sec:model}

In this section we provide a step-by-step exploitation model to
understand the process of carrying out application attacks based on
executable source code injection vulnerabilities.
Figure~\ref{fig:attacks} presents the steps of different application
attacks. For every arrow there is a
corresponding tuple that includes the step number for
every attack. For the most part, the steps are common in all attacks. This
is because they are based on similar attack vectors as we mentioned in
the previous section. Most importantly,
Figure~\ref{fig:attacks} also illustrates in which step
the defenses detect corresponding attacks ({\sc todo}).

A malicious user can initiate the attack through two different routes.
The attacker may use the browser of an innocent user as an attack
vehicle, through which the code will be injected in the application.
For example, the attacker could craft a malicious script into a {\sc url}
and then trick an end user to click on it via social engineering (i.e., phishing ---
{\sc step}: {\sc p-xss}' 1 \text{\textbar} {\sc n-xss}' 1 \text{\textbar} {\sc csrf} 1).
Alternatively, the attacker may be able to inject
directly the malicious code in the application. For example, consider
a web application that accepts and redisplays user input
without appropriate validation. An attacker could
upload data containing a specially crafted script (for example, in a
blog comment) to steal the cookies of the visiting users or embed
malicious {\sc sql} code to retrieve all the password entries from a
database ({\sc step}: {\sc dsl} 1 \text{\textbar}
{\sc p-xss} 1 \text{\textbar} {\sc n-xss} 1).
Note that an {\sc xss} attack can start from both routes.

Once the injected code reaches the vulnerable application, it becomes
a part of a value represented by a program variable. The target of the
attack determines the route from now on. In {\sc sql} injection and
{\sc csrf} attacks the injected code becomes part of a query that
finally reaches the database where it is executed. 

{\sc xss} attacks fall ino two categories, {\it non-persistent} and
{\it persistent}. Non-persistent {\sc xss} attacks take place when the
data provided by a user is used immediately by server-side scripts to
parse and display a page of results, without properly sanitizing the
request ({\sc step}: {\sc p-xss} 8 \text{\textbar} {\sc n-xss} 3).
Thus, in a non-persistent {\sc xss} attack the injected code
never reaches the database and immediately becomes a part of the
content that is sent back to a web user.

In persistent {\sc xss} attacks malicious code is saved by the server.
The injected code that is stored on the server-side re-enters the
application's execution flow and becomes part of the content that is
actually sent back afterwards to the user.

\begin{figure*}
\begin{center}
\leavevmode
\includegraphics[scale=0.61]{attacks-steps.pdf}
\end{center}
\caption{\label{fig:attacks}Attack model demonstrating web
application attacks based on executable source
code injection vulnerabilities. For every arrow there is a
corresponding tuple that includes the step number for
every attack. Note that {\sc xss} attacks can also involve
{\it phishing}. Every {\it locus} indicates a step where mechanisms
detect attacks. For every locus we provide the corresponding
references: ({\sc draft}).}
\end{figure*}

\section{Analysis Dimensions}
\label{sec:dimensions}

\subsection{Diagnostic Performance}

As in medical diagnostic tests, application attack defense mechanisms
must demonstrate the presence of an attack. This, however, does not
make an application attack defense mechanism immediately useful. In
order for a detection mechanism to be useful it must be accurate, easy to
use, and economical. The accuracy of a detection mechanism is gauged
with the following metrics~\cite{TDR2013,GFDLS06,A00}:
\begin{itemize}
\item {\bf Sensitivity}, the probability that an attack will be
  caught.
\item {\bf Specificity}, the probability that a normal interaction
  will test negative.
\item {\bf Positive Predictive Value} ({\sc ppv}), the probability that a
  reported attack is a real attack. It is the conditional probability
  that an event is an attack if the detection mechanism flags it as
  such. 
\item {\bf Negative Predictive Value} ({\sc npv}), the probability that if
  nothing is reported no attack has taken place. It is the conditional
  probability that an event is not an attack given that the detection
  mechanism flags it as normal.
\end{itemize}

Sensitivity and specifity are defined by way of the $2\times 2$
Table~\ref{tab:sensitivity-specificity}~\cite{linn2004}. 
In the cells of
the table we distinguish:
\begin{itemize}
\item True Positive ($a$), a real attack that raises an alarm.
\item True Negative ($d$), an event that is not an attack and that does
  not raise an alarm.
\item False Positive ($b$), an event that although it is not an attack
  raises an alarm.
\item False Negative ($c$), an event that although is as attack does
  not raise an alarm.
\end{itemize}

\noindent
With these we can calculate:

\begin{equation}
\textrm{SE} = \textrm{Sensitivity} = \frac{a}{a + c}
\end{equation}

\begin{equation}
\textrm{SP} = \textrm{Specificity} = \frac{d}{b + d}
\end{equation}

Sensitivity and specificity can be calculated based on test
data alone. To calculate the sensitivity, we run the test on a
controlled environment where we allow only attack events to reach the
system. The ratio of reported attacks over all attacks will give us
the sensitivity. Similarly, to calculate the specificity we can run
the test on a controlled environment where we allow only innocuous
events to reach the system. The ratio of non-reported events over all
events will give us the specificity. 

\begin{table}[ht]

\caption{Attacks and Test Outcomes in Test Environment}
\label{tab:sensitivity-specificity}

\begin{tabular}{l|l|c|c|}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Attack} \\ \cline{3-4}
\multicolumn{2}{c|}{} & Yes & No \\ \cline{2-4}
\multirow{2}{*}{Result} &  Yes &  $a = \textrm{True Positive}$ & 
$b = \textrm{False Positive}$ \\
& No & $c = \textrm{False Negative}$ & $d = \textrm{True Negative}$ \\ 
\cline{2-4}
\multicolumn{2}{r|}{Total} & $a + c$ & $b + d$ \\
\cline{3-4}
\end{tabular}

\end{table}

Note that the calculations are carried out vertically in
Table~\ref{tab:sensitivity-specificity}; the ratio of attack events to
normal events does not enter into sensitivity and specificity. This is
what allows us to derive them based on test data, without using data
from a real production environment. At the same time, however, this is
what limits their usefulness. When we obtain a test result in a
production environment, be it negative or positive, we really want to
know how much we should be worried, or relaxed. In other words, if an
attack is detected in a production environment, how much should we be
worried? If no attack is detected in a production environment, how
relaxed should we be that no attack has indeed taken place?

\begin{table}[ht]

\caption{Attacks and Test Outcomes in Real Environment}
\label{tab:ppv-npv}

\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Attack} & \\ \cline{3-4}
\multicolumn{2}{c|}{} & Yes & No & Total \\ \cline{2-5}
\multirow{2}{*}{Result} &  Yes &  $A = \textrm{True Positive}$ & 
$B = \textrm{False Positive}$ & \multicolumn{1}{c|}{$A + B$}\\
& No & $C = \textrm{False Negative}$ & $D = \textrm{True Negative}$ &
\multicolumn{1}{c|}{$C + D$}\\ 
\cline{2-5}
\end{tabular}

\end{table}

The answer to these questions is given by the \textsc{ppv} and the
\textsc{npv}. These depend not only on the test results, but also on
the \emph{prevalence} of attacks in real environments. In particular,
we can calculate them using Table~\ref{tab:ppv-npv}, which tabulates
results in a real environment, or in an environment where the
prevalence of attacks is equal to what we expect in the real world. To
indicate the difference with Table~\ref{tab:sensitivity-specificity}
we use capital letters for the entries in the table~\cite{linn2004}.
With this table, \textsc{ppv} and \textsc{npv} are given by the
following equations:

\begin{equation}
\textrm{PPV} = \frac{A}{A + C}
\end{equation}

\begin{equation}
\textrm{NPV} = \frac{D}{B + D}
\end{equation}

This time the ratios are taken horizontally; the ratio of attacks to
innocuous events affects the calculations. In fact, if PR is the
probability of attacks in the real world, the prevalence, then we
have~\cite{linn2004,altman1994}:

\begin{equation}
\textrm{PPV} = \frac{\textrm{SE}\times \textrm{PR}}{
\textrm{SE}\times \textrm{PR} + (1 - \textrm{SP})\times (1 -
\textrm{PR})}
\label{eq:ppv-se-sp}
\end{equation}

\begin{equation}
\textrm{NPV} = \frac{\textrm{SP}\times (1 - \textrm{PR})}{
(1 - \textrm{SE})\times \textrm{PR} + \textrm{SP}\times (1 -
\textrm{PR})}
\label{eq:npv-se-sp}
\end{equation}

The prevalence is the prior probability that an event is an attack,
based on our understanding of the volume and frequency of attacks; the
\textsc{ppv} and \textsc{npv} are the revised estimates of the
probability based on the results of the detection
mechanism~\cite{altman1994}. The lower the prevalence of an attack,
the more confident we can be that a negative test result indicates
that no attack has taken place and the less sure we can be that a
positive test result indicates a real attack. 

If published research does not include figures for Sensitivity and
Specificity or values for ($a$)--($d$), on test environments, then it
is not possible to judge the accuracy of the research at all. Even if
we do have such figures, a good research tool is not necessarily a
good practical tool. Even if a research tool scores well on
Sensitivity and Specificity, it may not be very useful in the real
world if the prevalence of the caught attacks is so low that a
positive test result is not likely to indicate a real attack.

To sum up, we evaluate diagnostic performance on two criteria:

\begin{itemize}
\item Reporting of Sensitivity and Specifity, either directly, or
  indirectly from published values of $a$--$d$.
\item Reporting of \textsc{ppv} and \textsc{npv}. This can be direct
  reporting of their values, or indirect from published values of
  $A$--$D$. Also, since from equations~\ref{eq:ppv-se-sp}
  and~\ref{eq:npv-se-sp} \textsc{ppv} and \textsc{npv} can be
  calculated by the sensitity and specifity given the prevalence, it
  can be via reporting prevalance, sensitivity, specificity.
\end{itemize}
 
\subsection{Computational Performance}

\subsection{Ease of Use}

\subsection{Security}

\subsection{Detection Locus}

\subsection{Availability}

\section{Defenses}
\label{sec:defs}

\begin{figure*} [ht]
\begin{center}
\leavevmode
\includegraphics[scale=0.65]{defenses.pdf}
\end{center}
\caption{\label{fig:defenses}The basic categories of web application
attack countermeasures ({\sc draft}).}
\end{figure*}

Figure~\ref{fig:defenses} presents a taxonomy of the
defenses that protect web applications against attacks based on
code injection vulnerabilities.
We can identify three main approaches, namely:
{\it design-based}, {\it behavior-based}
and {\it hybrid}.
The design-based category involves mechanisms that make applications
immune to different attack vectors by design~\cite{JL75,L81}.
The behavior-based incorporates a variety of methods and
schemes that inspect the behavior of applications
and detect attacks based on specific criteria~\cite{D76,A00}.
Hybrid mechanisms borrow characteristics from both categories.
Table~\ref{tab:comp} groups the various subcategories
and for every mechanism provides the following:

\begin{enumerate}
\item The number of citations of the publication(s) where
the mechanism was presented.
\item Quadruples that show the values of true
positives ({\sc tp}), true negatives ({\sc tn}),
false positives ({\sc fp}), and false negatives
({\sc tn}). For every quadruple there is a corresponding
suffix that indicates whether the testbed was based
on: real-world applications known to be vulnerable
(r), synthetic benchmarks (s), both (a).
If no testing has taken place we add a question
mark ({\bf ?}).
\item The computational overhead of the
mechanism as stated in the publication.
\item The attacks that the mechanism detects.
\end{enumerate}

\noindent
{\sc na} (Not Available) means that a requirement is not
mentioned in the paper. {\sc nq} (Not Quantified)
indicates that a requirement is mentioned in the publication
but it is not quantified.

Table~\ref{tab:avail} presents
our findings regarding the availability of the mechanism
in terms of source code and corresponding executables.
We also examined the availability of the testbeds mentioned in the paper.
The check mark (\tick) indicates that at some point within the publication,
there is a homepage where the reader can refer to, to download the
corresponding software. {\bf AO} (Available On-line) suggests that
the software is available on-line but the address was not mentioned
in the paper, which probably indicates that the authors made
it available after the publication. The question mark ({\bf ?}),
indicates that the a homepage for the software was included
in the publication but now it is not available.

Finally, as we mentioned in Subsection~\ref{sec:model},
Figure~\ref{fig:attacks} illustrates the point where
mechanisms detect attacks.

\subsection{Design-Based}
\label{sec:prot}

Here we analyze the three basic design-based approaches
used to protect web applications from the attacks we
discussed in Section~\ref{sec:attacks}.

\subsubsection{Parse-Tree Validation}
\label{sec:tree}

The key idea behind this approach, is to compare
the tree representation of the abstract syntactic
structure of the executable source code
with the one that was originally intended.
If the trees diverge, the application is probably
under attack.

In the case of {\sc dsl} injection attacks, mechanisms check 
the query before the inclusion of user input with the one
resulting after the inclusion of user input.
Both mechanisms that implement this approach,
{\sc sqlg}uard~\cite{BWS05} and
{\sc sql}check~\cite{SW06} are pretty similar
and detect the attack before a query reaches the
database (locus {\sc z}).
Contrary to {\sc sqlg}uard~\cite{BWS05} (and many other
mechanisms), {\sc sql}check~\cite{SW06} has been
extensively tested in terms of diagnostic performance
as seen in Table~\ref{tab:comp}. A disadvantage of
those mechanisms is that the application must be modified
every time a query is about to be sent to a database
for execution.

As we will see in Subsection~\ref{sec:hybrid},
there are mechanisms that borrow elements from
this approach and examine the syntax trees
of scripts to detect JavaScript-driven {\sc xss} attacks.

\subsubsection{Policy Enforcement}
\label{sec:policy}

This approach is used to detect attacks that target web users.
When using a framework that implements
this approach, developers must define
specific security policies on the server side.
Then the policies are enforced either in the user's
browser at runtime or in a server-side proxy that intercepts
server responses.

{\it Noxes}~\cite{KKVJ06,KJKV09} is the only
framework that partially allows the web
user to specify policies to prevent {\sc xss} attacks.
The key idea behind Noxes is to parse
the {\sc html} that reaches the browser to
find static {\sc url} references. Then, based on
a set of policies it allows or blocks
the request (locus {\sc x}). Such policies
are provided either by the user or by
the framework itself. Noxes does not
deal with JavaScript-driven {\sc xss}
attacks and it is a rather simplistic approach.

A number of the frameworks define policies
based on information and features provided by
the Document Object Model ({\sc dom}) of a web page.
Specifically, developers must place all legitimate
scripts inside {\sc html} elements like {\tt div}.
The web browser (locus {\sc x}), parses the
{\sc dom} tree and executes scripts only when they
are contained in such elements. All other scripts
are treated according to the policies defined
on the server. Frameworks that support this
functionality are {\sc beep}~\cite{TNH07}
and {\sc dsi}~\cite{NSS06}. The main problem with
the above mechanisms is that they are vulnerable
to non-persistent {\sc xss} attacks that alter
the {\sc dom} of an already rendered
page~\cite{APKLM10}.
In addition, a recent variation of JavaScript
injection attacks known as return-to-JavaScript
attack~\cite{APKLM10} can be used to bypass
the above mechanisms. Such attacks share
many similarities with the {\it return-to-lib}
attack~\cite{SPPGMMB04}. When performing an
attack like this the malicious user transfers the
execution to points that contain script
code which in turn is used to perform the attack.

Another policy enforcement approach introduces
policies directly either in {\sc html} or JavaScript code
to confine their behavior. {\it BrowserShield}~\cite{RDWDE07}
acts as a proxy on the server side (locus {\sc y}) to
parse the {\sc html} of server responses and identifies
scripts. Then, it rewrites them into safe equivalents
and protect the web user from exploitations
that are based on reported browser vulnerabilities.
{\it ConScript}~\cite{ML10}, {\it CoreScript}~\cite{YCIS07}
and the framework by {\it Phung et al.}~\cite{PSC09}
extend JavaScript with new primitive functions to
provide safe methods to protect potentially vulnerable
JavaScript functions. In both cases, policy enforcement takes
place on the JavaScript engine of the browser (locus {\sc x}).
In this way, {\sc xxs} attacks that take advantage
functions like {\tt eval} and {\tt write} that are
used to assemble innocuous-looking parts into harmful
strings would fail.

A critical issue regarding
the above frameworks is that they cannot
define policies that restrict the behavior of third-party
scripts introduced by script inclusion and {\tt iframe}
tags. For instance, consider a web page ({\tt foo.net})
that prints the value of the a query parameter ({\tt query})
from the page's {\sc url} in the web page's content
without escaping the value. A malicious user
can take advantage of this and inject an {\tt iframe}
into the page to steal the user's cookie and
send it via an image request to a web site
that he or she controls ({\tt malicious.com}).
This could be achieved by including the following
link to the malicious web site (or send it via phishing
email) and induce the user to click on it:

\lstset{language=VBScript, basicstyle=\footnotesize\ttfamily,}
\begin{lstlisting}
http://foo.net/vulnerable.html?query=
<iframe src="javascript:document.body.innerHTML=+
'<img src=\"http://malicious.com/?c=
'+encodeURIComponent(document.cookie)+'\">'">
</iframe>
\end{lstlisting}

\noindent
{\it WebJail}~\cite{VDDPJ11}, and
{\sc soma}~\cite{OWVS08} are two frameworks that
can actually detect such an attack (locus {\sc x}).
To achieve this, {\sc soma} requires site administrators
to specify legitimate, external domains for sending
or receiving information in order to approve interactions
between them and the protected web site. As a result,
{\sc soma} can also detect {\sc csrf} attacks.
WebJail contains the functionality of third-party scripts
by introducing a web component integrator that restricts
the access that these scripts may have to either the data
or the functionality of other components.

Policy enforcement mechanisms that detect {\sc csrf}
attacks are usually implemented in the form of a
server-side proxy (locus {\sc y})
interposing on the client-server communication, and modifying
it. {\it NoForge}~\cite{JKK06a}
parses the {\sc html} server responses
and adds a token to every {\sc url} referring to this
server. Then it associates the token with the cookie
representing the session {\sc id} for the application.
When a request is received, the mechanism checks
if the request contains the token related
to the session {\sc id}. A disadvantage of NoForge
is that {\sc html} that is dynamically created within
the browser will not include the token.
Thus, sites that create their {\sc html} on the client
will remain vulnerable. In addition, it does not
support cross-origin requests.
{\it j{\sc csrf}}~\cite{PS11}
has a very similar functionality and meanwhile
addresses the above problems.
Finally, {\it CsFire}~\cite{DDHPJ10}
examines cross-domain interactions,
to design a cross-domain policy.
The policy is based on the concept of a relaxed
same-origin policy that allows communication between
sub-domains of the same registered domain.

Most of the aforementioned frameworks, involve
several deployment issues since they
require significant source modifications by the web
developers in order to introduce policies.

\subsubsection{Instruction Set Randomization (ISR)}

{\sc isr} is a method that has been applied to counter
different kinds of application attacks~\cite{K09b,KKP03}.
The main idea behind the it, is to
separate code from data by randomizing the legitimate code's 
execution environment. In this way, the malicious code
injected by the attackers who do not know the randomization
algorithm, will not get executed.

{\it {\sc sql}rand}~\cite{BK04} is based on {\sc isr}
to detect {\sc sql} injections in the following manner:
initially, it allows programmers to create {\sc sql} statements
using randomized instructions instead of standard keywords.
The modified queries are reconstructed at runtime using
the same key that is inaccessible to the malicious user.
{\sc sql}rand is one of the few mechanisms that
detect {\sc sql} injection attacks on the database
level (locus $\Omega$).

In the case of {\sc xss} attacks that are based on JavaScript
or {\sc html}, consider a {\sc xor} function that encodes all source of a web
page on the server-side and then, on the client-side, the web browser decodes the
source by applying the same function again (locus {\sc x}).
Variations of this approach include:
{\it Noncespaces}~\cite{GC09} and {\it x{\sc js}}~\cite{APKLM10}
which randomize the instruction set of {\sc html} and
JavaScript respectively.
Contrary to x{\sc js}, in Noncespaces administrators must set
specific policies in a manner similar to a firewall
configuration language. This brings up questions
concerning the diagnostic performance of the mechanism
since the corresponding testing is insufficient
(see Table~\ref{tab:comp}).
{\it {\sc sm}ask}~\cite{JB07} is another framework
that was inspired by {\sc isr}. To detect {\sc xss}
attacks it searches for {\sc html} and JavaScript
keywords within the application's legitimate code.
This is done before the processing of an {\sc http}
request. When it finds one it adds a token to it.
This results to a ``code mask". Then,
before sending the resulting {\sc html} data to the
web user, the framework searches the data for
illegal code by using the same keywords (locus {\sc y}).
Since all legitimate code has been ``masked",
the injected code can be identified.
The pre- and post-processing of the code though,
may add a significant overhead to the application.
Unfortunately, the authors of {\sc sm}ask
did not provide measurements regarding the
computational performance of the tool (see Table~\ref{tab:comp}).

{\sc isr} is a deterministic approach that can be applied
to detect different attacks in an efficient manner.
However, Sovarel et al.~\cite{SEP05}
have investigated thoroughly the effectiveness
of {\sc isr} and showed that a malicious user
may be able to circumvent it by determining
the randomization key and their results
indicate that doing {\sc isr} in a way that
provides a certain degree of security against a motivated
attacker is more difficult than previously thought.
Furthermore, developers who wish to use
such mechanisms must follow good coding practices
and never show a randomized code statement in any case
(i.e. an exception error) because in this way
they will reveal the encoding key.

Even though the above implementations impose a low
computational overhead, they impose an infrastructure
overhead. In particular, in the case of {\sc sql}rand
the integration of a proxy within the database server
is required while Noncespaces and x{\sc js} require
modifications on both the server and the client.

\subsection{Behavior-Based}

In this section we examine the two main behavior-based
approaches.

\subsubsection{Taint Tracking}
\label{sec:taint}

A taint tracking scheme marks untrusted
(``tainted") data (for instance, a variable set
by a field in a web form) and traces its flow through
the program. If the variable is used in an expression
that sets another variable, that variable is also
marked as untrusted and so on. If any of these variables
is used to execute a potentially risky command (``sink") the
scheme may act accordingly.

Taint tracking is provided as a feature in some
programming languages, such as Perl and Ruby.
By enabling the feature, Perl would refuse to run code
vulnerable to an {\sc sql} injection attack
(consider a tainted variable being used in a query)
and exit with an error message.

There are different implementations of these approach
in terms of how the tainted data is marked and observed,
and how attacks are detected.
For example, {\it Haldar et al.}~\cite{HCF05} have implemented
their scheme for the Java Virtual Machine ({\sc jvm})
where they instrument various classes. When a
tainted string is used as an argument to a sink method
then an exception is raised (locus {\sc z}).
However, this is a simplistic approach that may
lead to many false positives.
The following schemes apply further checks when
they identify that tainted data have reached a sink.
In particular, {\it Xu et al.}~\cite{XBS06}
tracks taint information at the level of bytes in memory.
To distinguish between legitimate and malicious uses
of untrusted data that reach a sink,
they search the data for suspicious symbols by using
regular expressions. {\sc csse}~\cite{PB05} associates
tainted data with specific metadata. Such metadata include
the origins of tainted data, its propagation within the application
and other. When tainted data reaches a sink {\sc csse} performs
syntactic checks it based on the aforementioned metadata
(locus {\sc z}). {\it {\sc php} Aspis}~\cite{PMP11} works
in a similar way. To obtain metadata, it takes advantage
of specific features provided by {\sc php}.
Note that the above schemes detect potential attacks
in locus {\sc z}. This automatically means that they
cannot detect non-persistent JavaScript-driven
{\sc xss} attacks. Although they can be
modified to do so. {\sc wasc}~\cite{NLC07} 
though, can deal with such attacks because it
analyzes {\sc html} responses to check
if there are tainted data that contain scripts (locus {\sc y}).
A recent study showed that there are ways to circumvent
the majority of the above schemes~\cite{NBR14}.
Furthermore, most of them are hard to deploy since
the majority of input vectors, string operations
and output vectors must be instrumented.

{\it Vogt et al.}~\cite{VFJKKV07}
have developed a tainting scheme that follows a different
approach. Contrary to the aforementioned schemes that
operate on the server side, they track taint sensitive
information on the client side (locus {\sc x}).
This is a form of positive taint tracking, where
taint data is considered to be legitimate.
Their scheme detects JavaScript-driven {\sc xss}
attacks by ensuring that a script can send sensitive
user data only to the site from which it came from.
This though, may lead to false alarms.
{\it Stock et al.}~\cite{SLMS14} propose a scheme
that also operates in the browser (locus {\sc x}).
The scheme focuses on the detection of
{\sc dom}-based {\sc xss} attacks.
In such an attack, the malicious payload is
executed as a result of the modification of the
{\sc dom} environment so that the client-side
code runs in an unanticipated manner even if the
{\sc http} response that triggers the injection seems legitimate.
The scheme is different to the previous one because it
marks and observes data that are considered harmful.
Specifically, it employs a taint-enhanced JavaScript
engine that tracks the flow of attacker-controlled data.
To detect potential attacks the scheme utilizes
{\sc html} and JavaScript parsers that can
identify the generation of code coming from
tainted data.

% @dimitro: move this to the analysis Section:
% This scheme is an efficient scheme that focuses
% on a specific category of {\sc xss} attacks and
% takes into consideration many attack vectors
% that many of the previous schemes do not.
% Also: 
% As the author of {\sc csse} state~\cite{PB05}, the prevention
% of {\sc xss} attack requires a more complex analysis.

\subsubsection{Training}

Training techniques are based on the ideas of Denning's original
intrusion detection framework~\cite{Den87}. In particular, a training
mechanism registers all valid legitimate code statements during a
training phase, most of the time in the form of signatures. This can
be done in various ways according to the implementation. Then, only
those will be accepted, approved or recognized during production.

Training methods that detect {\sc dsl}-driven injection attacks
generate and store valid code statements (i.e. {\sc sql}
or {\sc xp}ath queries) in various forms, and detect attacks
as outliers from the set of valid code statements.
An early approach, {\it {\sc didafit}}~\cite{LLW02} detects
{\sc sql} injection (locus $\Omega$) attacks by recording all database transactions.
Subsequent refinements by Valeur et al.~\cite{VMV05}
tagged each transaction with the corresponding application
as an extension of their anomaly detection framework called
{\it libAnomaly}. {\it {\sc sd}river}~\cite{MS09,MKS09} is
a signature-based mechanism that prevents {\sc sql} and
{\sc xp}ath injection attacks. The signatures generated
during a training phase, are based on features that can
depend either on the code statement or on its execution
environment (i.e. the stack trace).
Then, at runtime, the mechanism checks all statements for compliance
and can block code statements containing injected elements (locus {\sc z}).
Furthermore, {\sc amnesia}~\cite{HO05,HO06,HO05b} is a tool
that also detects {\sc sql} injection attacks (locus {\sc z})
by associating a query model with the location of every
{\sc sql} statement within the application.
Then at runtime, monitors the application's execution to
detect when {\sc sql} statements diverge from the expected model.

In the case of {\sc xss} attacks the various countermeasures
follow a similar pattern. {\it {\sc swap}}~\cite{WPLKK09}
creates a unique identifier ({\it script {\sc id}}) for
every legitimate script on the server.
Then, a JavaScript detection component placed in a
web proxy (locus {\sc y}) searches for injected scripts
with no corresponding {\sc id} in the server's responses.
If no injected scripts are found, the proxy forwards the
request to the client. This mechanism is relatively
inflexible since it does not support dynamic scripts.
In addition it imposes a significant overhead (see Table~\ref{tab:comp}).
The authors of {\it {\sc xssds}}~\cite{JEP08}
have implemented a similar mechanism that also supports
dynamic and external scripts. Specifically,
during training phase they build a list of all benign scripts.
In the case of external scripts they keep a white list
of all the valid domain names that contain scripts
used by the application.

The training subcategory, includes some mechanisms
that can be easily circumvented. For example,
consider an application that will send the password 
for a forgetful user via email by executing
the following query:
\bgroup
\lstset{language=SQL}
\begin{small}
\begin{lstlisting}
SELECT password from userdata WHERE id = 'Alice'
\end{lstlisting}
\end{small}
\egroup
\noindent
This same application could allow users to lock their terminal,
but allow the unlocking either with the user's password or with
the administrator password (the 4.3 {\sc bsd} {\em lock} command
behaved in this peculiar way).
The corresponding query to verify the password on the locked
workstation would be as follows:
\bgroup
\lstset{language=SQL}
\begin{small}
\begin{lstlisting}
SELECT password from userdata WHERE id = 'Alice' OR
id = 'admin'
\end{lstlisting}
\end{small}
\egroup
\noindent
A traditional {\sc sql} injection attack protection system like {\sc didafit},
could be easily escaped since a malicious user, could obtain the
administrator's password by email by entering on the password retrieval form
as his user identifier the following:
\bgroup
\lstset{language=SQL}
\begin{small}
\begin{lstlisting}
nosuchuser' OR id = 'admin
\end{lstlisting}
\end{small}
\egroup
\noindent
However, mechanisms that create signatures that involve
elements not only associated with the code statements
(i.e. {\sc amnesia} and {\sc sd}river)
could detect such attacks. Specifically,
{\sc sd}river associates a complete stack trace with the
root of an {\sc sql} statement, thus it can correlate
queries with their call sites and detect attacks
like the aforementioned one.
Furthermore, training tools that detect
{\sc xss} attacks based on JavaScript injection
would fail to detect a return-to-JavaScript attack
like the one mentioned in Subsubsection~\ref{sec:policy}.

In general, the detection accuracy of training approaches is
heavily based on the coverage that is achieved during the
training phase. If the coverage is insufficient the
production of false alarms is very likely.
In addition, when a code statement is altered, a new
training phase is necessary.

All the above mechanisms are relatively easy to deploy.
{\sc dsl} injection attack countermeasures
can be retrofitted to a system typically by changing
some configuration files. This does not apply
to {\sc amnesia} though, since significant source code
modifications are required for every query that exists
in the application. Finally, {\sc swap} and {\sc xssds}
are implemented within a proxy on the server-side.

\subsection{Hybrid}
\label{sec:hybrid}

This category includes mechanisms that borrow
characteristics from more than one of the above categories.
Two of them focus on the detection of {\sc xss}
attacks and one of them focuses on {\sc dsl} code
injection attacks.

{\sc xss-guard}~\cite{BV08} is a training scheme
that also employs parse-tree validation.
During training, the scheme maps legitimate scripts
to {\sc http} responses. During production
{\sc xss-guard} retrieves for every script included
in a response its parse-tree and checks if it
is one of those previously mapped to this response.
Apart from the comparison of the parsed-trees, {\sc xss-guard}
checks also for an exact match of lexical entities.
To achieve this, the scheme utilizes that data structures
of Firefox's JavaScript engine (locus {\sc x}).
However, string literals are not compared literally
thus, a possible false negative result could occur if an
adversary performed a mimicry attack~\cite{WS02}.
For example, consider a banner rotator that
every time it runs, it creates a value that depends on
the current date and the length of the array that
contains the references of the various images to be displayed.
Then, based on this value it shows a specific
image to a user. In a vulnerable web site that allows
users to post data and contains this banner
rotator, a malicious user could create and store a script
that has the same code structure, with the same JavaScript
keywords like the above. In this script the
attacker could also include references to tiny
images hosted on a web server that is maintained by him in order
to retrieve the {\sc ip} addresses of the
users that visit the vulnerable site.

{\it Blueprint}~\cite{LV09} is a policy
enforcement framework that also utilizes parsed-trees
to detect {\sc xss} attacks. To guarantee
that untrusted content is not executed, Blueprint generates
on the server-side a parse-tree from untrusted {\sc html}
to ensure that it does not contain any dynamic content.
Then the parsed-tree is transfered to the document
generator of the browser (locus {\sc x}) where untrusted
browser parsing behavior is ruled out.
Blueprint is an efficient countermeasure but it
imposes a significant overhead due to its
extensive parsing (see Table~\ref{tab:comp}).

{\it Diglossia}~\cite{SMS13} combines positive taint tracking
(see Subsubsection~\ref{sec:taint}) together with
parse-tree validation. Diglossia was based on the
theory of Ray and Ligatti~\cite{RL12b} (also see
Section~\ref{sec:attacks}) to detect {\sc dsl}
code injection attacks. In addition, it is actually
the first, and so far the only framework that detects
No{\sc sql} injection attacks.
When an application computes an output string (query),
Diglossia computes a ``shadow" of this string.
Specifically, it maps all characters introduced by
the application to a shadow character set.
This set does not contain any characters coming
from the tainted input. Then, the scheme
creates the parse-tree of the query that
is about to be executed with the parse-tree
of the ``shadow" and compares them (locus {\sc z}).
If the trees are not equal the application is probably
under attacks. Diglossia can be bypassed in the same
way as other taint tracking approaches~\cite{NBR14}.

\begin{landscape}
\begin{table}
    \caption{Comparison summary of mechanisms developed to counter application attacks based on executable source code injection.}
    \label{tab:comp}
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|c|cc|c}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
	& \bf{\# of Citations}
  & \multicolumn{2}{|c|}{Requirements\tnote{1}}
	& \bf{Attack} \\
	&&& \bf{TP,TN,FP,FN}\tnote{2}
	& \bf{Computational Overhead} & \\
    \hline
  \multirow{2}{*}{Parse-Tree Validation}
  &   {\it {\sc sqlg}uard}~\cite{BWS05} & 243 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 3\% & {\sc sql} injection \\
  &   {\it {\sc sqlc}heck}~\cite{SW06} & 402 & (36848,7648,0,0)\_r & 3ms per query & {\sc sql} injection \\
  \hline
  \hline
  \multirow{12}{*}{Policy Enforcement}
  &   {\it {\sc dsi}}~\cite{NSS06} & 135 & (5268,{\sc nq},46,15)\_r & 1.85\% & {\sc xss} \\ 
  &   {\it NoForge}~\cite{JKK06a} & 35 & (7,{\sc nq},{\sc nq},0)\_r & {\bf ?} & {\sc csrf} \\
  &   {\it Noxes}~\cite{KKVJ06,KJKV09} & 268,40 & (3,{\sc na},{\sc na},0)\_r & {\sc na} & {\sc xss} \\
  % &   {\it {\sc met}}~\cite{ELX07} & 58 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc xss} \\ 
  &   {\it {\sc beep}}~\cite{TNH07} & 282 & (61,{\sc na},{\sc na},0)\_r & 14.4\% & {\sc xss} \\
  &   {\it BrowserShield}~\cite{RDWDE07} & 219 & (19,{\sc nq},0,0,)\_r & 8\% & {\sc xss} \\ 
  &   {\it CoreScript}~\cite{YCIS07} & 181 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_s & {\sc nq} & {\sc xss} \\
  &   {\it {\sc soma}}~\cite{OWVS08} & 46 & (5,{\sc na},{\sc na},0)\_s & 5.58\% & {\sc xss}, {\sc csrf} \\
  % &   {\it Barth et al.}~\cite{BJM08} & 271 & & {\bf ?} & {\sc csrf} \\
  &   {\it Phung et al.}~\cite{PSC09} & 75 & (37,{\sc na},{\sc na},4)\_r & 5.37\% & {\sc xss} \\
  &   {\it ConScript}~\cite{ML10} & 122 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 7\% & {\sc xss} \\
  &   {\it CsFire}~\cite{DDHPJ10} & 35 & (419582,1141807,0,3)\_r\tnote{3} & {\bf ?} & {\sc csrf} \\
  &   {\it j{\sc csrf}}~\cite{PS11} & 2 & (2,{\sc na},{\sc na},0)\_r & 2ms & {\sc csrf} \\
  &   {\it WebJail}~\cite{VDDPJ11} & 25 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & $\sim$7ms & {\sc xss} \\
  % &   {\it TreeHouse}~\cite{IW12} & 18 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 757–-1218ms & {\sc xss} \\
  % &   {\it {\sc js}and}~\cite{AVBPDP12} & 22 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & up to 31.2\% & {\sc xss}\\
  % \hline
  % \hline 
  % \multirow{3}{*}{Securing Mashups}
  % &   {\it {\sc om}ash}~\cite{CHC08} & 58 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc nq} & {\sc csrf} \\
  % &   {\it Mashup{\sc os}}~\cite{WFHJ07} & 149 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 1--59\% & {\sc xss} \\
  \hline
  \hline
  \multirow{4}{*}{{\sc isr}}
  &   {\it {\sc sql}rand}~\cite{BK04} & 286 & (3,{\sc na},{\sc na},0)\_a & $\le$6.5{\it ms} & {\sc sql} injection \\
  &   {\it {\sc sm}ask}~\cite{JB07} & 27 & (5,{\sc nq},{\sc nq},{\sc nq})\_r  & {\sc na} & {\sc sql} injection, {\sc xss} \\
  &   {\it Noncespaces}~\cite{GC09} & 109 & ({\sc nq},{\sc na},{\sc na},0)\_r &  10.3\% & {\sc xss} \\ 
  &   {\it x{\sc js}}~\cite{APKLM10} & 18 & (1380,{\sc na},{\sc na},1)\_r & 1.6--40{\it ms} & {\sc xss} \\
  \hline
  \hline
	\multirow{7}{*}{Taint Tracking}
  &   {\it Haldar et al.}~\cite{HCF05} & 177 & (2,{\sc na},{\sc na},0)\_s & {\sc nq} & {\sc sql} injection, {\sc xss} \\ 
	&  	{\sc csse}~\cite{PB05} & 312 & (7,{\sc nq},{\sc nq},{\sc nq})\_r & 2--10\% & {\sc sql} injection, {\sc xp}ath, {\sc xss} \\
	% &  	{\it SecuriFly}~\cite{MLL05} & 31 & \xmark,\tick & 9--125\% & {\sc sql} injection, {\sc xss} \\ 
	&  	{\it Xu et al.}~\cite{XBS06} & 297 & (9,{\sc nq},0,{\sc nq})\_r & average 76\% & {\sc sql} injection, {\sc xss} \\ 
  &  	{\it {\sc wasc}}~\cite{NLC07} & 31 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & up to 30\% & {\sc sql} injection, {\sc xss} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07} & 322 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_r & {\sc nq} & {\sc xss} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & 12 & (12,{\sc nq},{\sc nq},2)\_r & 2.2$\times$ & {\sc sql} and {\sc php} injection, {\sc xss} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & 0 & (1169,{\sc na},{\sc na},0)\_r & 7--17\% & {\sc dom}-based {\sc xss} \\
	\hline
	\hline  
  \multirow{6}{*}{Training}
  &   {\it {\sc didafit}}~\cite{LLW02} & 85 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc sql} injection \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & 118,66,376 & (1470,{\sc nq},0,0)\_a & {\sc nq} & {\sc sql} injection \\ 
	&   {\it libAnomaly}~\cite{VMV05} & 226 & (344,15646,60,0)\_r & +1{\it ms} & {\sc sql} injection \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & 64 & ({\sc nq},{\sc nq},{\sc nq},0)\_r & {\sc nq} &  {\sc xss} \\
  & 	{\it {\sc swap}}~\cite{WPLKK09} & 52 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & $\sim$180\% & {\sc xss} \\ 
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & 21,8,5 & (241,{\sc nq},0,0)\_a & 39\% & {\sc sql} and {\sc xp}ath injection \\
	% & 	{\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} & 9,40,1 & \xmark,\xmark  & \xmark & {\sc sql} and {\sc xp}ath injection \\
  \hline
  \hline
  \multirow{3}{*}{Hybrid}
  &   {\it {\sc xss-guard}}~\cite{BV08} & 97 & (8,{\sc nq},{\sc nq},{\sc nq})\_r & 5--24\% & {\sc xss} \\
  &   {\it Blueprint}~\cite{LV09} & 110 & (94,{\sc na},{\sc na},0)\_r & 13.6\% & {\sc xss} \\
  &   {\it Diglossia}~\cite{SMS13} & 4 & (9,{\sc nq},{\sc nq},{\sc nq})\_r & 13\% & {\sc sql} and No{\sc sql} injection \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       	\item[1] {\sc na} (Not Available) means that a requirement is not mentioned in the paper.
	{\sc nq} (Not Quantified) indicates that a requirement is mentioned in the publication
	but it is not quantified.
		\item[2] For every quadruple there is a corresponding suffix that indicates whether the testbed was
	based on: a) real-world applications known to be vulnerable ({\it r}), b) synthetic benchmarks ({\it s}), c) both ({\it a}).
	If no testing has taken place we add a question mark ({\bf ?}).
    \item[3] The number involve requests.
	\end{footnotesize}
    \end{tablenotes}
    \end{small}
    \end{threeparttable}
\end{table}
\end{landscape}

\section{Analysis}

Notes on taint tools:
\begin{enumerate}
\item The accuracy testing of {\sc csse}~\cite{PB05} was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item During their evaluation, the authors of~\cite{HCF05} have only performed
two attacks in one synthetic benchmark ({\sc owasp}'s
{\it WebGoat}\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_WebGoat_Project}}).
\item The testing in~\cite{XBS06} was made based on
defects with specific {\sc cve id}s.
\item The authors of {\it {\sc wasc}}~\cite{NLC07}
mention the vulnerabilities (specific {\sc cve id}s)
exploited and the corresponding applications but they do not explicitly
state how many attacks they launched (``{\it [...] launched a variety of
attacks against it}").
\item The authors of~\cite{VFJKKV07} do the same.
However, even if they do not mention specific {\sc cve id}s,
they browsed applications without performing attacks.
\item Even if the authors of {\it Noxes}~\cite{KKVJ06,KJKV09} state in
both papers that ``{\it [...] we are planning to make the tool available as
a freeware utility}." the tool cannot be found anywhere on the Internet.
The vulnerabilities exploited during testing were reported
by {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item {\it {\sc php} Aspis}~\cite{PMP11} was tested on only one
application (Wordpress 2.9.2) with multiple vulnerabilities (specific {\sc cve id}s).
\item During their initial tests, the authors of
managed to bypass the browser-based {\sc xss} filters of the
73\% of 1,602 real-world {\sc dom}-based {\sc xss} vulnerabilities.
Then they proposed an approach that detected all the attacks they
found (1169). This is a complex paper --- we need to elaborate.
\end{enumerate}

Notes on {\sc isr} mechanisms:
\begin{enumerate}
\item {\it {\sc sql}rand}~\cite{BK04}: Both exploits from {\sc cve} --- though
this is not mentioned in the publication.
\item {\it Noncespaces}~\cite{GC09} was only tested on one
known vulnerable application (TikiWiki). The authors mention that they performed
a number of attacks but they do not state how many.
\item The authors of {\it x{\sc js}}~\cite{APKLM10}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\end{enumerate}

Notes on policy enforcement tools:
\begin{enumerate}
\item Just like the authors of {\it x{\sc js}~\cite{APKLM10},
the authors of {\sc dsi}}~\cite{NSS06}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\item The testing of {\it BrowserShield}~\cite{RDWDE07}
involved {\sc xss} vulnerabilities reported by Microsoft
in 2005.\footnote{\url{https://technet.microsoft.com/en-us/security/bulletin}}
The link currently shows defects for 2014.
\item {\it CoreScript}~\cite{YCIS07} is more of a programming
language\footnote{``[...] uses program instrumentation for
JavaScript where untrusted JavaScript
code goes through a rewriting process according to a security policy
before executing them in the browser"~\cite{PSC09}.}
than an {\sc IDS}.
\item Surprisingly, {\sc met}~\cite{ELX07} was not tested at all.
\item {\sc beep}~\cite{TNH07}'s test suite was based on 61 {\sc xss}
attack vectors published by \url{ha.ckers.org}.
\item {\sc soma}~\cite{OWVS08} --- all synthetics.
\item The attacks used for the testing of {\it Blueprint}~\cite{LV09},
came from \url{ha.ckers.org}.
\item {\it Phung et al.}~\cite{PSC09} also utilized \url{ha.ckers.org}.
\item {\it WebJail}~\cite{VDDPJ11} --- not tested at all.
\item {\it ConScript}~\cite{ML10} --- not tested at all. A scheme
similar to {\it CoreScript}~\cite{YCIS07}.
\item {\it j{\sc csrf}}~\cite{PS11} --- based on {\sc csrf}
defects with specific {\sc cve id}s.
\item The authors of {\it TreeHouse}~\cite{IW12} have tested
only the overhead and how easy is to incorporate the mechanism
into an application.
\end{enumerate}

Notes on training-based mechanisms:
\begin{enumerate}
\item {\it {\sc didafit}}~\cite{LLW02} is one of
the first {\sc ids}.
\item {\sc amnesia}~\cite{HO05,HO06,HO05b} was tested
on applications with known vulnerabilities taken
from \url{http://gotocode.com} plus two synthetic benchmarks.
Interestingly, in one of the papers~\cite{HO06},
the authors mention that the tool can produce both {\sc fp} and
{\sc fn}.
\item {\it libAnomaly}~\cite{VMV05} --- one application tested ({\sc php}-Nuke).
\item {\sc sqlg}uard~\cite{BWS05} --- no testing at all.
\item {\sc sm}ask~\cite{JB07} was tested on real-world applications
with exploits from {\sc cve} --- though this is not mentioned in the publication.
\item {\sc xssds}~\cite{JEP08} --- testing was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
The authors provide multiple {\sc fp} rates depending on the experiment.
\item {\sc xss-guard}~\cite{BV08} was tested on real-world applications
with exploits from {\sc cve}.
\item {\sc swap}~\cite{WPLKK09} was tested on a real-world application ({\sc phpbb})
with exploits from {\sc cve} --- though this is not mentioned in the publication.
%\item {\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} have developed a
%mechanism to detect {\sc sql} and {\sc xp}ath injection attacks
%only on web services. Their testing involve a real-world benchmark
%({\sc tpc}-app).\footnote{\url{http://www.tpc.org/}}
\item {\it Diglossia}~\cite{SMS13} was tested on real-world applications
with exploits from {\sc cve}.
\end{enumerate}

Notes:
\begin{enumerate}
\item Note that most mechanisms that implement design-based
approaches have not been extensively tested in terms of
diagnostic performance.
\item We need to mention that there are mechanisms that
do not need to be established purely through testing
Since they provide systematic arguments as to why
the design is secure against attacks.
\item Policy enforcement is the
only approach that is
used to prevent {\sc csrf} attacks.
\item See j{\sc csrf} for {\sc soma}'s drawbacks.
\end{enumerate}

\begin{table*}
\caption{Availability of the corresponding mechanisms.}
    \label{tab:avail}
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|ccc}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
  & \multicolumn{3}{|c|}{Availability\tnote{1}} \\
	&& \bf{Source Code}
	& \bf{Executable}
	& \bf{Testbed} \\
    \hline
  \multirow{2}{*}{Parse-Tree Validation}
  &   {\it {\sc sqlc}heck}~\cite{SW06} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it {\sc sqlg}uard}~\cite{BWS05} & {\bf AO} & {\bf AO} & {\sc na} \\
  \hline  
  \hline
  \multirow{12}{*}{Policy Enforcement}
  &   {\it {\sc dsi}}~\cite{NSS06} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it NoForge}~\cite{JKK06a} & {\bf AO} & {\bf AO} & {\sc na} \\
  &   {\it Noxes}~\cite{KKVJ06,KJKV09}  & {\sc na} & {\sc na} & {\sc na} \\
  % &   {\it {\sc met}}~\cite{ELX07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it {\sc beep}}~\cite{TNH07} & \tick & \tick & \tick \\
  &   {\it BrowserShield}~\cite{RDWDE07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it CoreScript}~\cite{YCIS07} & {\bf AO} & {\sc na} & {\sc na} \\
  &   {\it {\sc soma}}~\cite{OWVS08} & {\sc na} & {\sc na} & {\sc na} \\
  % &   {\it Barth et al.}~\cite{BJM08} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Phung et al.}~\cite{PSC09} & \tick & \tick & \tick \\
  &   {\it ConScript}~\cite{ML10} & {\bf AO} & {\sc na} & {\sc na} \\
  &   {\it CsFire}~\cite{DDHPJ10} & \tick & {\sc na} & {\sc na} \\
  &   {\it j{\sc csrf}}~\cite{PS11} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it WebJail}~\cite{VDDPJ11} & {\sc na} & {\sc na} & {\sc na} \\
    % &   {\it {\sc js}and}~\cite{AVBPDP12} & {\sc na} & {\sc na} & {\sc na} \\
  % \hline
  % \hline 
  % \multirow{3}{*}{Securing Mashups}
  % &   {\it {\sc om}ash}~\cite{CHC08} & {\sc na} & {\sc na} & {\sc na} \\
  % &   {\it Mashup{\sc os}}~\cite{WFHJ07} & {\sc na} & {\sc na} & {\sc na} \\
  % &   {\it TreeHouse}~\cite{IW12} & {\sc na} & {\sc na} & {\sc na} \\
  \hline
  \hline
  \multirow{4}{*}{{\sc isr}}
  &   {\it {\sc sql}rand}~\cite{BK04} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it {\sc sm}ask}~\cite{JB07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Noncespaces}~\cite{GC09} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it x{\sc js}}~\cite{APKLM10} & {\sc na} & {\sc na} & {\sc na} \\
  \hline
  \hline 
	\multirow{7}{*}{Taint Tracking}
	&  	{\it Haldar et al.}~\cite{HCF05}  & {\sc na} & {\sc na} & {\sc na} \\
  &   {\sc csse}~\cite{PB05} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Xu et al.}~\cite{XBS06}  & {\sc na} & {\sc na} & {\sc na} \\
  &  	{\it {\sc wasc}}~\cite{NLC07} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07}  & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & {\bf AO} & {\sc na} & {\bf AO} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & {\sc na} & {\sc na} & {\sc na} \\
  \hline
  \hline 
  \multirow{6}{*}{Training}
  &   {\it {\sc didafit}}~\cite{LLW02} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & {\sc na} & {\bf AO} & {\sc na} \\
	&   {\it libAnomaly}~\cite{VMV05} & {\bf ?} & {\bf ?} & {\bf ?} \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & {\sc na} & {\sc na} & {\sc na} \\
  & 	{\it {\sc swap}}~\cite{WPLKK09} & {\sc na} & {\sc na} & {\sc na} \\
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & \tick & \tick & {\sc na} \\
  \hline
  \hline
  \multirow{3}{*}{Hybrid}
  &   {\it {\sc xss-guard}}~\cite{BV08} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Blueprint}~\cite{LV09} & {\bf ?} & {\bf ?} & {\bf ?} \\
  &   {\it Diglossia}~\cite{SMS13} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       \item[1] The check mark (\tick) indicates that the publication
       includes a homepage where the reader can refer to, to
       download the corresponding software. {\bf AO} (Available On-line) suggests
       that the software is available on-line but the
       address was not mentioned in the paper, which probably indicates that
       the authors made it available after the publication. The question ({\bf ?})
       mark, indicates that the a homepage for the software was included
       in the publication but now it is not available.
	\end{footnotesize}
    \end{tablenotes}
    \end{small}
    \end{threeparttable}
\end{table*}

\section{Conclusions}

% Cite~\cite{HNSHS12}.

\bibliographystyle{IEEEtran}
\bibliography{questioning}

\end{document} 

