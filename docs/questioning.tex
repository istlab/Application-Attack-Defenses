\documentclass[conference]{IEEEtran}

\usepackage{hyperref}
%\usepackage{graphicx}
\usepackage{fancyhdr}
%\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{color}
\usepackage{url}
%\usepackage{moreverb}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{mathptmx}
\usepackage{dingbat}
\usepackage{pifont}
\usepackage{acronym}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{supertabular}
\usepackage{listings}
\usepackage{threeparttable}
\usepackage{pdflscape}
\usepackage{array}
\usepackage{multirow}
\usepackage{subfigure}

\usepackage[numbers,sort]{natbib}

\renewcommand{\algorithmiccomment}[1]{\hfill {\tt //} #1}
\newcommand{\tick}{\ding{52}}
\newcommand{\xmark}{\ding{56}}

\date{}
\begin{document}

\author{
\IEEEauthorblockN{Dimitris Mitropoulos,\IEEEauthorrefmark{1}
Panos Louridas,\IEEEauthorrefmark{2} and Angelos Keromytis\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}
Network Security Lab\\
Department of Computer Scinence\\
Columbia University\\
\{dimitro, angelos\}@cs.columbia.edu\\
\IEEEauthorrefmark{2}
Software Engineering and Security Lab\\
Department of Management Science and Technology\\
Athens University of Economics and Business\\
louridas@aueb.gr
}}

\title{SoK: Application Attack Defenses (in Question)}

\maketitle
\begin{abstract}
In this paper we examine how application attack defense
mechanism are developed and presented to
the research community.
\end{abstract}

\begin{IEEEkeywords}
Security and Protection, Application Security, Code injection Attacks, Cyber Security Experiments, Effectivenes, Efficiency.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}

Introduction~\cite{I05}. Also see~\cite{A00}.

Requirements:
\begin{itemize}
\item {\bf Flexibility} We check if an approach
can be adjusted in order to detect different {\sc cia} categories.
\item {\bf Ease of use} We examine if the mechanism that
implements an approach is practical and can be easily adopted
by security experts.
\item {\bf Effectiveness} As long as we examine security
mechanisms that detect either attacks or defects,
the non-existence of false positive and negative alarms
is a reasonable requirement.
\item {\bf Efficiency} Finally, we examine
the computational overhead of the mechanisms that affect the experience of
a web user who actually uses the protected application.
\item {\bf Security} How resilient is the system to
attacks made to to circumvent it.
\end{itemize}
All the aforementioned requirements are considered critical
when building security mechanisms that protect
applications~\cite{A01,A00}.

\section{Methodological Background}

As in medical diagnostic tests, application attack defense mechanisms
must demonstrate the presence of an attack. This, however, does not
make an application attack defense mechanism immediately useful. In
order for a detection mechanism to be useful it must accurate, easy to
use, and economical. The accuracy of a detection mechanism is gauged
with the following metrics:
\begin{itemize}
\item {\bf Sensitivity}, the probability that an attack will be
  caught.
\item {\bf Specificity}, the probability that a normal interaction
  will test negative.
\item {\bf Positive Predictive Value} (PPV), the probability that a
  reported attack is a real attack.
\item {\bf Negative Predictive Value} (NPV), the probability that if
  nothing is reported no attack has taken place.
\end{itemize}

For example, a simple announcement that an attach defense mechanism
catches an attack says very little about the usability and
applicability of the mechanism. There may be some value in indicating
that detection \emph{per se} is possible, if that has been considered
infeasible in the past. Most value, though, comes from knowing the
answers to questions like the following, which correspond to the
previous metrics:
\begin{itemize}
\item Does it catch all the attacks? If not, how many of them?
\item Does it catch only attacks? If not, how many false alarms would
  we expect?
\item How much should we be worried if we do get an alarm?
\item How much at ease should we be if no alarm is raised?
\end{itemize}

Sensitivity, specificity, PPV, and NPV, are defined precisely by way
of the $2\times 2$ Table~\ref{tab:attacks-outcomes}. In the cells of
the table we distinguish:
\begin{itemize}
\item True Positive (TP), a real attack that raises an alarm.
\item False Positive (FP), an event that although it is not an attack
  raises an alarm.
\item True Negative (TN), an event that is not an attack and that does
  not raise an alarm.
\item False Negative (FN), an event that although is as attack does
  not raise an alarm.
\end{itemize}

With these we can calculate:

\begin{equation}
\textrm{sensitivity} = \frac{\textrm{TP}}{\textrm{TP} + \textrm{TN}}
\end{equation}

\begin{equation}
\textrm{specificity} = \frac{\textrm{TP}}{\textrm{TN} + \textrm{FP}}
\end{equation}

\begin{equation}
\textrm{PPV} = \frac{\textrm{TP}}{\textrm{TP} + \textrm{FP}}
\end{equation}

\begin{equation}
\textrm{NPV} = \frac{\textrm{TN}}{\textrm{TN} + \textrm{FN}}
\end{equation}

\begin{table}[ht]

\caption{Attacks and Test Outcomes}
\label{tab:attacks-outcomes}

\begin{tabular}{l|l|c|c|}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Attack} \\ \cline{3-4}
\multicolumn{2}{c|}{} & Yes & No \\ \cline{2-4}
\multirow{2}{*}{Result} &  Yes &  True Positive & False Positive \\
& No & False Negative & True Negative \\ \cline{2-4}
\end{tabular}

\end{table}

Sensitivity and specificity can be calculated based on test results
alone. To calculate the sensitivity, we run the test on a controlled
environment where we allow only attack events to reach the system. The
ratio of reported attacks over all events will give us the
sensitivity. Similarly, to calculate the specificity we can run the
test on a controlled environment where we allow only innocuous events
to reach the system. The ratio of non-reported events over all events
will give us the specificity. 

The calculation of PPV and NPV requires that we evaluate the attack
defense mechanism on a real operational environment where the events
are a mix of attacks and innocuous events and, moreover, the mix ratio
is the ratio of attacks over harmless events that exists in actual
operations. Too few or too many attacks will skew metrics calculations.

The last requirement may seem cumbersome, but consider that, in actual
operations, PPV is what would determine our actions. Administrators
will limited resources need to allocate their attention judiciously.
They may need to prioritize responses to emergency warnings; the PPV
value will indicate them what priority to give to a raised alarm.

\section{Covered Area}

We decided to narrow down our
research to countermeasures developed to
detect attacks that target applications. Such attacks include
buffer overflow attacks~\cite{K11}, {\sc sql} injection
attacks~\cite{RL12b}, cross-site scripting ({\sc xss})
attacks~\cite{SG07}, cross-site request forgery ({\sc csrf})
attacks~\cite{LZRL09} and others.
Such attacks top the vulnerability lists of numerous bulletin providers for several
years.\footnote{\url{http://www.sans.org/top-cyber-security-risks/}, \url{http://cwe.mitre.org/top25/}}
Consider the {\sc owasp}\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}
(Open Web Application Security Project)
Top Ten project whose main goal is to raise awareness about
web application security by identifying some of the most critical risks facing
organizations which is referenced by numerous researchers.
In its three consecutive Top Ten lists (2007, 2010, 2013), different
source code-driven injection attacks dominate the top five positions.
This indicates that
apart from the fact that malicious users find new ways to bypass
defense mechanisms by using a variety of techniques despite the numerous
countermeasures that are being introduced.
Note that the number of systems developed to counter {\sc sql}
injection attacks until 2006 was more than twenty~\cite{HVO06}.
Since then the number has doubled.
In our research we focus on the top {\sc tba} systems that counter
application attacks, in terms of citations.
% TODO@dimitro: explain why you leave out {\it SecuriFly}~\cite{MLL05}.

\begin{landscape}
\begin{table}
%\tbl{Performance of System Prototype. Time is Measured in $\mu$s.}{
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|c|cc|c}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
	& \bf{\# of Citations}
    & \multicolumn{2}{|c|}{Requirements\tnote{1}}
	& \bf{Attack} \\
	&&& \bf{TP,TN,FP,FN}
	& \bf{Computational Overhead} & \\
    \hline
	\multirow{9}{*}{Runtime Tainting}
	&  	{\sc csse}~\cite{PB05} & 312 & (7,{\sc nq},{\sc nq},{\sc nq})\_r & 2--10\% & {\sc sql} injection \\
	&  	{\it Haldar et al.}~\cite{HCF05} & 177 & (2,{\sc na},{\sc na},0)\_s & {\sc nq} & {\sc sql} injection, {\sc xss} \\ 
	% &  	{\it SecuriFly}~\cite{MLL05} & 31 & \xmark,\tick & 9--125\% & {\sc sql} injection, {\sc xss} \\ 
	&  	{\it Xu et al.}~\cite{XBS06} & 297 & (9,{\sc nq},0,{\sc nq})\_r & average 76\% & {\sc sql} injection, {\sc xss}, Buffer Overflows \\ 
    &  	{\it {\sc wasc}}~\cite{NLC07} & 31 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & up to 30\% & {\sc sql} injection, {\sc xss} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07} & 322 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_r & {\sc nq} & {\sc xss} \\
	&   {\it Noxes}~\cite{KKVJ06,KJKV09} & 268,40 & (3,{\sc na},{\sc na},0)\_r & {\sc na} & {\sc xss} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & 12 & (15,{\sc nq},{\sc nq},{\sc nq})\_r & 2.2$\times$ & {\sc sql} and {\sc php} injection, {\sc xss} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & 0 & (1169,{\sc na},{\sc na},0)\_r & 7--17\% & {\sc dom}-based {\sc xss} \\
	\hline
	\hline      
	\multirow{3}{*}{{\sc isr}}
	&   {\it {\sc sql}rand}~\cite{BK04} & 286 & (3,{\sc na},{\sc na},0)\_a & +6.5{\it ms} & {\sc sql} injection \\ 
	&   {\it Noncespaces}~\cite{GC09} & 109 & ({\sc nq},{\sc na},{\sc na},0)\_r &  10.3\% & {\sc xss} \\ 
    &   {\it x{\sc js}}~\cite{APKLM10} & 18 & (1380,{\sc na},{\sc na},1)\_r & 1.6--40{\it ms} & {\sc xss} \\
	\hline
	\hline    
	\multirow{12}{*}{Policy Enforcement}
	&   {\it {\sc dsi}}~\cite{NSS06} & 135 & (5268,{\sc nq},46,15)\_r & 1.85\% & {\sc xss} \\ 
	&   {\it BrowserShield}~\cite{RDWDE07} & 219 & (19,{\sc nq},0,0,)\_r & 8\% & {\sc xss} \\ 
	&   {\it CoreScript}~\cite{YCIS07} & 181 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_s & {\sc nq} & {\sc xss} \\ 
	&   {\it {\sc met}}~\cite{ELX07} & 58 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc xss} \\ 
    &   {\it {\sc beep}}~\cite{TNH07} & 282 & (61,{\sc na},{\sc na},0)\_r & 14.4\% & {\sc xss} \\
    &   {\it {\sc soma}}~\cite{OWVS08} & 46 & (5,{\sc na},{\sc na},0)\_s & 5.58\% & {\sc xss}, {\sc csrf}\\
	&   {\it Blueprint}~\cite{LV09} & 110 & (94,{\sc na},{\sc na},0)\_r & 13.6\% & {\sc xss} \\ 
	&   {\it Phung et al.}~\cite{PSC09} & 75 & (37,{\sc na},{\sc na},4)\_r & 5.37\% & {\sc xss} \\
	&   {\it WebJail}~\cite{VDDPJ11} & 25 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & $\sim$7ms & {\sc xss} \\ 
	&   {\it ConScript}~\cite{ML10} & 122 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 7\% & {\sc xss} \\
	&   {\it j{\sc csrf}}~\cite{PS11} & 2 & (2,{\sc na},{\sc na},0)\_r & 2ms & {\sc csrf} \\
    &   {\it TreeHouse}~\cite{IW12} & 18 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 757–-1218ms & {\sc xss} \\
   	% &   {\it {\sc js}and}~\cite{AVBPDP12} & 22 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & up to 31.2\% & {\sc xss}\\
   	% TODO@dimitro: discuss this with Panos?
	\hline
	\hline  
        \multirow{11}{*}{Training}
    &   {\it {\sc didafit}}~\cite{LLW02} & 85 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc sql} injection \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & 118,66,376 & (1470,{\sc nq},0,0)\_a & {\sc nq} & {\sc sql} injection \\ 
	&   {\it libAnomaly}~\cite{VMV05} & 226 & (344,15646,60,0)\_r & +1{\it ms} & {\sc sql} injection \\
	& 	{\it {\sc sqlg}uard}~\cite{BWS05} & 243 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 3\% & {\sc sql} injection \\
	& 	{\it {\sc sm}ask}~\cite{JB07} & 27 & (5,{\sc nq},{\sc nq},{\sc nq})\_r  & {\sc na} & {\sc sql} injection, {\sc xss} \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & 64 & ({\sc nq},{\sc nq},{\sc nq},0)\_r & {\sc nq} &  {\sc xss} \\
    & 	{\it {\sc xss-guard}}~\cite{BV08} & 97 & (8,{\sc nq},{\sc nq},{\sc nq})\_r & 5--24\% & {\sc xss} \\
    & 	{\it {\sc swap}}~\cite{WPLKK09} & 52 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & $\sim$180\% & {\sc xss} \\ 
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & 20,8,5 & (241,{\sc nq},0,0)\_a & 39\% & {\sc sql} and {\sc xp}ath injection \\
	% & 	{\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} & 9,40,1 & \xmark,\xmark  & \xmark & {\sc sql} and {\sc xp}ath injection \\
	& 	{\it Diglossia}~\cite{SMS13} & 3 & (9,{\sc nq},{\sc nq},{\sc nq})\_r & 13\% & {\sc sql} and No{\sc sql} injection \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       \item[1] {\sc na} (Not Available) means that a requirement is not even mentioned in the paper.
	{\sc nq} (Not Quantified) indicates that a requirement is mentioned in the publication
	but it is not quantified.
	\end{footnotesize}
    \end{tablenotes}
    \caption{Comparison summary of mechanisms developed to counter application attacks.}
    \label{tab:comp2}
    \end{small}
    \end{threeparttable}
\end{table}
\end{landscape}

\section{Analysis}

Notes on taint tools:
\begin{enumerate}
\item The accuracy testing of {\sc csse}~\cite{PB05} was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item During their evaluation, the authors of~\cite{HCF05} have only performed
two attacks in one synthetic benchmark ({\sc owasp}'s
{\it WebGoat}\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_WebGoat_Project}}).
\item The testing in~\cite{XBS06} was made based on
defects with specific {\sc cve id}s.
\item The authors of {\it {\sc wasc}}~\cite{NLC07}
mention the vulnerabilities (specific {\sc cve id}s)
exploited and the corresponding applications but they do not explicitly
state how many attacks they launched (``{\it [...] launched a variety of
attacks against it}").
\item The authors of~\cite{VFJKKV07} do the same.
However, even if they do not mention specific {\sc cve id}s,
they browsed applications without performing attacks.
\item Even if the authors of {\it Noxes}~\cite{KKVJ06,KJKV09} state in
both papers that ``{\it [...] we are planning to make the tool available as
a freeware utility}." the tool cannot be found anywhere on the Internet.
The vulnerabilities exploited during testing were reported
by {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item {\it {\sc php} Aspis}~\cite{PMP11} was tested on only one
application (Wordpress 2.9.2) with multiple vulnerabilities (specific {\sc cve id}s).
\item During their initial tests, the authors of
managed to bypass the browser-based {\sc xss} filters of the
73\% of 1,602 real-world {\sc dom}-based {\sc xss} vulnerabilities.
Then they proposed an approach that detected all the attacks they
found (1169). This is a complex paper --- we need to elaborate.
\end{enumerate}

Notes on {\sc isr} mechanisms:
\begin{enumerate}
\item {\it {\sc sql}rand}~\cite{BK04}: Both exploits from {\sc cve} --- though
this is not mentioned in the publication.
\item {\it Noncespaces}~\cite{GC09} was only tested on one
known vulnerable application (TikiWiki). The authors mention that they performed
a number of attacks but they do not state how many.
\item The authors of {\it x{\sc js}}~\cite{APKLM10}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\end{enumerate}

Notes on policy enforcement tools:
\begin{enumerate}
\item Just like the authors of {\it x{\sc js}~\cite{APKLM10},
the authors of {\sc dsi}}~\cite{NSS06}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\item The testing of {\it BrowserShield}~\cite{RDWDE07}
involved {\sc xss} vulnerabilities reported by Microsoft
in 2005.\footnote{\url{https://technet.microsoft.com/en-us/security/bulletin}}
The link currently shows defects for 2014.
\item {\it CoreScript}~\cite{YCIS07} is more of a programming
language\footnote{``[...] uses program instrumentation for
JavaScript where untrusted JavaScript
code goes through a rewriting process according to a security policy
before executing them in the browser"~\cite{PSC09}.}
than an {\sc IDS}.
\item Surprisingly, {\sc met}~\cite{ELX07} was not tested at all.
\item {\sc beep}~\cite{TNH07}'s test suite was based on 61 {\sc xss}
attack vectors published by \url{ha.ckers.org}.
\item {\sc soma}~\cite{OWVS08} --- all synthetics.
\item The attacks used for the testing of {\it Blueprint}~\cite{LV09},
came from \url{ha.ckers.org}.
\item {\it Phung et al.}~\cite{PSC09} also utilized \url{ha.ckers.org}.
\item {\it WebJail}~\cite{VDDPJ11} --- not tested at all.
\item {\it ConScript}~\cite{ML10} --- not tested at all. A scheme
similar to {\it CoreScript}~\cite{YCIS07}.
\item {\it j{\sc csrf}}~\cite{PS11} --- based on {\sc csrf}
defects with specific {\sc cve id}s.
\item The authors of {\it TreeHouse}~\cite{IW12} have tested
only the overhead and how easy is to incorporate the mechanism
into an application.
\end{enumerate}

Notes on training-based mechanisms:
\begin{enumerate}
\item {\it {\sc didafit}}~\cite{LLW02} is one of
the first {\sc ids}.
\item {\sc amnesia}~\cite{HO05,HO06,HO05b} was tested
on applications with known vulnerabilities taken
from \url{http://gotocode.com} plus two synthetic benchmarks.
Interestingly, in one of the papers~\cite{HO06},
the authors mention that the tool can produce both {\sc fp} and
{\sc fn}.
\item {\it libAnomaly}~\cite{VMV05} --- one application tested ({\sc php}-Nuke).
\item {\sc sqlg}uard~\cite{BWS05} --- no testing at all.
\item {\sc sm}ask~\cite{JB07} was tested on real-world applications
with exploits from {\sc cve} --- though this is not mentioned in the publication.
\item {\sc xssds}~\cite{JEP08} --- testing was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
The authors provide multiple {\sc fp} rates depending on the experiment.
\item {\sc xss-guard}~\cite{BV08} was tested on real-world applications
with exploits from {\sc cve}.
\item {\sc swap}~\cite{WPLKK09} was tested on a real-world application ({\sc phpbb})
with exploits from {\sc cve} --- though this is not mentioned in the publication.
%\item {\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} have developed a
%mechanism to detect {\sc sql} and {\sc xp}ath injection attacks
%only on web services. Their testing involve a real-world benchmark
%({\sc tpc}-app).\footnote{\url{http://www.tpc.org/}}
\item {\it Diglossia}~\cite{SMS13} was tested on real-world applications
with exploits from {\sc cve}.
\end{enumerate}

\begin{table*}
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|ccc}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
    & \multicolumn{3}{|c|}{Availability\tnote{1}} \\
	&& \bf{Source Code}
	& \bf{Executable}
	& \bf{Testbed} \\
    \hline
	\multirow{9}{*}{Runtime Tainting}
	&  	{\sc csse}~\cite{PB05} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Haldar et al.}~\cite{HCF05}  & {\sc na} & {\sc na} & {\sc na} \\
	% &  	{\it SecuriFly}~\cite{MLL05}  & - & - & - \\
	&  	{\it Xu et al.}~\cite{XBS06}  & {\sc na} & {\sc na} & {\sc na} \\
    &  	{\it {\sc wasc}}~\cite{NLC07} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07}  & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it Noxes}~\cite{KKVJ06,KJKV09}  & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & {\sc ao} & {\sc na} & {\sc ao} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline      
	\multirow{3}{*}{{\sc isr}}
	&   {\it {\sc sql}rand}~\cite{BK04} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it Noncespaces}~\cite{GC09} & {\sc na} & {\sc na} & {\sc na} \\
    &   {\it x{\sc js}}~\cite{APKLM10} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline    
	\multirow{12}{*}{Policy Enforcement}
	&   {\it {\sc dsi}}~\cite{NSS06} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it BrowserShield}~\cite{RDWDE07} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it CoreScript}~\cite{YCIS07} & {\sc ao} & {\sc na} & {\sc na} \\
	&   {\it {\sc met}}~\cite{ELX07} & {\sc na} & {\sc na} & {\sc na} \\
    &   {\it {\sc beep}}~\cite{TNH07} & \tick & \tick & \tick \\
    &   {\it {\sc soma}}~\cite{OWVS08} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it Blueprint}~\cite{LV09} & {\bf ?} & {\bf ?} & {\bf ?} \\
	&   {\it Phung et al.}~\cite{PSC09} & \tick & \tick & \tick \\
	&   {\it WebJail}~\cite{VDDPJ11} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it ConScript}~\cite{ML10} & {\sc ao} & {\sc na} & {\sc na} \\
	&   {\it j{\sc csrf}}~\cite{PS11} & {\sc na} & {\sc na} & {\sc na} \\
    &   {\it TreeHouse}~\cite{IW12} & {\sc na} & {\sc na} & {\sc na} \\
   	% &   {\it {\sc js}and}~\cite{AVBPDP12} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline  
        \multirow{11}{*}{Training}
    &   {\it {\sc didafit}}~\cite{LLW02} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & {\sc na} & {\sc ao} & {\sc na} \\
	&   {\it libAnomaly}~\cite{VMV05} & {\bf ?} & {\bf ?} & {\bf ?} \\
	& 	{\it {\sc sqlg}uard}~\cite{BWS05} & {\sc ao} & {\sc ao} & {\sc na} \\
	& 	{\it {\sc sm}ask}~\cite{JB07} & {\sc na} & {\sc na} & {\sc na} \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & {\sc na} & {\sc na} & {\sc na} \\
    & 	{\it {\sc xss-guard}}~\cite{BV08} & {\sc na} & {\sc na} & {\sc na} \\
    & 	{\it {\sc swap}}~\cite{WPLKK09} & {\sc na} & {\sc na} & {\sc na} \\
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & \tick & \tick & {\sc na} \\
	% & 	{\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} & {\bf ?} & {\bf ?} & {\bf ?} \\
	& 	{\it Diglossia}~\cite{SMS13} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       \item[1] The check mark (\tick) indicates that some point within
       the publication there is a homepage where the reader can refer to, to
       download the corresponding software. {\sc ao} (Available On-line) suggests
       that the software is available on-line but the
       address was not mentioned in the paper, which probably indicates that
       the authors made it available after the publication. The question ({\bf ?})
       mark, indicates that the a homepage for the software was included
       in the publication but now it is not available.
	\end{footnotesize}
    \end{tablenotes}
    \caption{Availability of the corresponding mechanisms.}
    \label{tab:comp2}
    \end{small}
    \end{threeparttable}
\end{table*}

\bibliographystyle{IEEEtran}
\bibliography{questioning}

\end{document} 

