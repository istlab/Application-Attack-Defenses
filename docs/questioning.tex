\documentclass[conference]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{fancyhdr}
%\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{color}
\usepackage{url}
%\usepackage{moreverb}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{mathptmx}
\usepackage{dingbat}
\usepackage{pifont}
\usepackage{acronym}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{supertabular}
\usepackage{listings}
\usepackage{threeparttable}
\usepackage{pdflscape}
\usepackage{array}
\usepackage{multirow}
\usepackage{subfigure}

\usepackage[numbers,sort]{natbib}

\renewcommand{\algorithmiccomment}[1]{\hfill {\tt //} #1}
\newcommand{\tick}{\ding{52}}
\newcommand{\xmark}{\ding{56}}

\date{}
\begin{document}

\author{
\IEEEauthorblockN{Dimitris Mitropoulos,\IEEEauthorrefmark{1}
Panos Louridas,\IEEEauthorrefmark{2},
Michalis Polychronakis,\IEEEauthorrefmark{1}
and Angelos Keromytis\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}
Network Security Lab\\
Department of Computer Scinence\\
Columbia University\\
\{dimitro, mikepo, angelos\}@cs.columbia.edu\\
\IEEEauthorrefmark{2}
Software Engineering and Security Lab\\
Department of Management Science and Technology\\
Athens University of Economics and Business\\
louridas@aueb.gr
}}

\title{SoK: The Evolution of Defenses Against Web Application Attacks}

\maketitle
\begin{abstract}

  Some of the most dangerous web application attacks, like Cross-Site
  Scripting and {\sc sql} injection, exploit the oversight of
  programmers that develop applications which may accept and process
  data of uncertain origin without appropriate validation and / or
  filtering. Such attacks, relying on source code injection
  vulnerabilities, have been constantly topping the lists of the
  various security bulletin providers despite the numerous
  countermeasures that have been proposed over the past 15 years.

  In this paper we systematize the existing knowledge regarding
  various defense mechanisms against source code injection by setting
  up a model that highlights the key weaknesses behind such attacks and
  helps us observe defenses from a common perspective.

  We then categorize and analyze the various defense mechanisms that
  have been developed. Our analysis is based on dimensions such as
  accuracy, performance, deployment and security. Especially notable
  for a key category is accuracy, as our findings show that there are
  many defense mechanisms that are tested in a poor manner.

  By comparing the existing defenses and identifying their common
  characteristics, we help: a) researchers and practitioners to choose
  or modify a mechanism according to their needs, and b) designers of
  new approaches in developing more efficient mechanisms.
% @dimitro: change the above accordingly.


%In this paper we examine how application attack defense
%mechanism are developed and presented to
%the research community.
\end{abstract}

\begin{IEEEkeywords}
Security and Protection, Application Security, Code injection Attacks.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction Remarks}

Web application attacks may involve security misconfigurations,
broken authentication and session management, or other issues.
Some of the most dangerous web application attacks, though,
are associated with the processing of external input data
that may contain malicious code, a vulnerability known as
code injection.

Such attacks include Cross-Site Scripting ({\sc xss})
attacks~\cite{SG07}, {\sc sql} injection attacks~\cite{RL12b},
Cross-Site Request Forgery ({\sc csrf}) attacks~\cite{LZRL09}, and
others. Attacks like these have been topping the vulnerability lists
of numerous bulletin providers like the Open Web Application Security
Project\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project}}
({\sc owasp}) and
{\sc mitre}\footnote{\url{http://cwe.mitre.org/top25/}} for several
years. Consider the case of {\sc owasp}'s Top Ten project whose main
goal is to raise awareness about web application security by
identifying some of the most critical risks facing organizations which
is referenced by numerous researchers. In its three consecutive Top
Ten lists (2007, 2010, 2013), different executable source code-driven
injection attacks dominate the top five positions. Malicious users
find new ways to bypass defense mechanisms by using a variety of
techniques despite the numerous countermeasures that are being
introduced. Note that the number of systems developed to counter
{\sc sql} injection attacks until 2006 was more than twenty~\cite{HVO06}.
Since then the number has doubled.
Researchers have also indicated that the number of such attacks
is steadily increasing in recent years~\cite{SSL12}.

There is already a survey on mitigating
software vulnerabilities in general~\cite{SZ12}.
The scope of that research is pretty wide and leaves
out many approaches and mechanisms that we report here.
This is mainly because this work includes countermeasures
that detect such vulnerabilities via program analysis
(which is done during development or testing), while
we include protection mechanisms that counter
such attacks when they take place.
Also, countermeasures that prevent {\sc sql}
injection attacks~\cite{HVO06}, have already been surveyed.
However, this survey is quite old and since then
the number of countermeasures that detect {\sc sql}
injection attacks alone, has been drastically increased
as we mentioned in the previous paragraph.
In our research we focus on the top
{\sc tba} systems that counter application attacks,
in terms of citations.

% TODO@dimitro: explain why you leave out {\it SecuriFly}~\cite{MLL05}.

Introduction~\cite{I05}. Also see~\cite{A00}.

Requirements:
\begin{itemize}
\item {\it Diagnostic Performance} As long
as we examine protection mechanisms that detect
attacks, the non-existence of false positive and
negative alarms is a reasonable requirement.
\item {\it Computational Performance} We examine
the overhead of the mechanisms
that affect the experience of a web user who actually
uses the protected application.
\item {\it Ease of use} We examine if the protection
mechanism is practical in terms of deployment
and can be easily adopted by security experts.
\item {\it Security} How resilient is the system to
attackers that know how it works and wants to circumvent it.
\item {\it Detection Locus}
\item {\it Availability}
\end{itemize}

All the aforementioned requirements are considered critical
when building security mechanisms that protect
applications~\cite{A01,A00}.

\section{Attacks}
\label{sec:attacks}

The basic problem behind the most dangerous
web application attacks involves
the absence of input validation. By taking advantage of
this, attackers can inject their code into
applications to perform malicious tasks. Such
an exploit can have different forms depending on the
execution context of the application and the location
of the programming flaw that leads to the attack.

Bratus et al.~\cite{BLSPS11} portray the issue in a generic fashion:
{\it ``unexpected (and unexpectedly powerful) computational models
inside targeted systems, which turn a part of the target into a
so-called `weird machine' programmable by the attacker via crafted inputs
(a.k.a. `exploits')''}.
An example of the above definition is the
following: The code fragment below defines the operation of
addition in the Scheme programming language~\cite{AS96,D09}:

\begin{verbatim}
(define (add x y) (+ x y))
\end{verbatim}

\noindent
Consider the case where instead of a number, a function that leads to an
endless loop is passed as an argument by the user. This will cause
the interpreter to enter
an endless loop and lead to a denial of service.
% Keep in mind that a {\sc cia} does not require a programming
% language with first-class functions.
The intuition here is that {\it ``every application that copies
untrusted input verbatim into an output
program is vulnerable to code injection''}.
Ray and Ligatti~\cite{RL12b} actually proved the above
claim based on formal language theory.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[scale=0.47]{attack-tree-uml.pdf}
\end{center}
\caption{\label{fig:taxonomy}A taxonomy of executable source
code injection attacks.}
\end{figure}

Code injection attacks can be divided into two categories. The first
involves binary code and the second executable source code. An
extensive survey on binary code injection attacks can be found
in~\cite{LC03}. Specific advances in exploiting such vulnerabilities
(i.e. ``heap smashing", ``arc injection" and others) have been
presented in~\cite{PB04}. The countermeasures used to detect such
defects have already been surveyed~\cite{YJP12} (many of them are also
included in a book:~\cite{DKZ12} -- Section 13.8). In the present work
we do not include binary code injection, focusing instead on defenses
that protect applications against application attacks based on the
executable source code injection category.

\subsection{Executable Source Code Injection Vulnerabilities}

Figure~\ref{fig:taxonomy} presents a taxonomy of executable source
code injection attacks. Such attacks may involve source code, either of a
{\it Domain Specific Language} ({\sc dsl}) or a {\it Dynamic Language}.

Application attacks that involve {\sc dsl}s constitute an important
subset of the code injection problem, as {\sc dsl}s like {\sc sql} and
{\sc xml} play an significant role in the development of either web or
mobile applications. For example, many applications have interfaces
where a user enters input to interact with the application's data,
thereby interacting with the underlying Relational Database Management
System ({\sc rdbms}). This input can become part of an {\sc sql} query
and executed on the target {\sc rdbms}. A code injection attack that
exploits the vulnerabilities of these interfaces by taking advantage
of input validation issues like incorrectly passed parameters or
incorrect type handling, is called an {\sc sql} injection
attack~\cite{CERT02,MS09,HVO06,SW06}. By using similar techniques
malicious users can perform other exploits based on {\sc dsl}s, like
{\sc xp}ath~\cite{SW06,CDL07,MKS09} and {\sc xml}~\cite{MSM13}. With
this kind of attacks, a malicious user can view sensitive information,
destroy or modify protected data, or even crash the entire
application. {\sc html} is another {\sc dsl} that can be used
for malicious purposes when an application does not properly
handle user supplied data. Based on this vulnerability
an attacker can supply valid {\sc html},
typically via a parameter value, and inject their own
content into the page. {\sc html} injection is mainly associated
with {\sc xss} defects.

A recent class of {\sc cia}s involve dynamic languages like
JavaScript and {\sc php}~\cite{SFVM09,EWKK09,SMS13}. JavaScript
injection attacks, in particular, make up a large subset of dynamic
language-driven attacks. Such attacks are manifested when a web
application accepts and redisplays data of uncertain origin without
appropriate validation and filtering. Based on this flaw, an attacker
can manage to inject a script in the JavaScript engine of a browser
and alter its execution flow~\cite{ELX07}. JavaScript injection
attacks are considered as a critical issue in web application security
mainly because they are associated with major vulnerabilities such as:
{\sc xss} attacks~\cite{SG07}, {\sc csrf} attacks~\cite{LZRL09} and
Cross-Channel Scripting ({\sc xcs}) attacks~\cite{W10,BBB09}.
In many cases {\sc xss} attacks involve the injection of
both {\sc html} and JavaScript code.

% {\sc html} injection --- such attacks pose no threat to cookies and session IDs.

\subsection{Exploitation Model}
\label{sec:model}

In this section we provide a step-by-step exploitation model to
understand the process of carrying out application attacks based on
executable source code injection vulnerabilities.
Figure~\ref{fig:attacks} presents the steps of different application
attacks. For every arrow there is a
corresponding tuple that includes the step number for
every attack. For the most part, the steps are common in all attacks. This
is because they are based on similar attack vectors as we mentioned in
the previous section. Most importantly,
Figure~\ref{fig:attacks} also illustrates in which step
the defenses detect corresponding attacks ({\sc todo}).

A malicious user can initiate the attack through two different routes.
The attacker may use the browser of an innocent user as an attack
vehicle, through which the code will be injected in the application.
For example, the attacker could craft a malicious script into a {\sc url}
and then trick an end user to click on it via social engineering (i.e., phishing ---
{\sc step}: {\sc p-xss}' 1 \text{\textbar} {\sc n-xss}' 1 \text{\textbar} {\sc csrf} 1).
Alternatively, the attacker may be able to inject
directly the malicious code in the application. For example, consider
a web application that accepts and redisplays user input
without appropriate validation. An attacker could
upload data containing a specially crafted script (for example, in a
blog comment) to steal the cookies of the visiting users or embed
malicious {\sc sql} code to retrieve all the password entries from a
database ({\sc step}: {\sc dsl} 1 \text{\textbar}
{\sc p-xss} 1 \text{\textbar} {\sc n-xss} 1).
Note that an {\sc xss} attack can start from both routes.

Once the injected code reaches the vulnerable application, it becomes
a part of a value represented by a program variable. The target of the
attack determines the route from now on. In {\sc sql} injection and
{\sc csrf} attacks the injected code becomes part of a query that
finally reaches the database where it is executed. 

{\sc xss} attacks fall ino two categories, {\it non-persistent} and
{\it persistent}. Non-persistent {\sc xss} attacks take place when the
data provided by a user is used immediately by server-side scripts to
parse and display a page of results, without properly sanitizing the
request ({\sc step}: {\sc p-xss} 8 \text{\textbar} {\sc n-xss} 3).
Thus, in a non-persistent {\sc xss} attack the injected code
never reaches the database and immediately becomes a part of the
content that is sent back to a web user.

In persistent {\sc xss} attacks malicious code is saved by the server.
The injected code that is stored on the server-side re-enters the
application's execution flow and becomes part of the content that is
actually sent back afterwards to the user.

\begin{figure*}
\begin{center}
\leavevmode
\includegraphics[scale=0.55]{attacks-steps.pdf}
\end{center}
\caption{\label{fig:attacks}Attack model demonstrating web
application attacks based on executable source
code injection vulnerabilities. For every arrow there is a
corresponding tuple that includes the step number for
every attack. Note that {\sc xss} attacks can also involve
{\it phishing}. Every {\it locus} indicates a step where mechanisms
detect attacks. For every locus we provide the corresponding
references: ({\sc draft}).}
\end{figure*}

\section{Analysis Dimensions}
\label{sec:dimensions}

\subsection{Diagnostic Performance}

As in medical diagnostic tests, application attack defense mechanisms
must demonstrate the presence of an attack. This, however, does not
make an application attack defense mechanism immediately useful. In
order for a detection mechanism to be useful it must be accurate, easy to
use, and economical. The accuracy of a detection mechanism is gauged
with the following metrics~\cite{TDR2013,GFDLS06,A00}:
\begin{itemize}
\item {\bf Sensitivity}, the probability that an attack will be
  caught.
\item {\bf Specificity}, the probability that a normal interaction
  will test negative.
\item {\bf Positive Predictive Value} ({\sc ppv}), the probability that a
  reported attack is a real attack. It is the conditional probability
  that an event is an attack if the detection mechanism flags it as
  such. 
\item {\bf Negative Predictive Value} ({\sc npv}), the probability that if
  nothing is reported no attack has taken place. It is the conditional
  probability that an event is not an attack given that the detection
  mechanism flags it as normal.
\end{itemize}

Sensitivity and specifity are defined by way of the $2\times 2$
Table~\ref{tab:sensitivity-specificity}~\cite{linn2004}. 
In the cells of
the table we distinguish:
\begin{itemize}
\item True Positive ($a$), a real attack that raises an alarm.
\item True Negative ($d$), an event that is not an attack and that does
  not raise an alarm.
\item False Positive ($b$), an event that although it is not an attack
  raises an alarm.
\item False Negative ($c$), an event that although is as attack does
  not raise an alarm.
\end{itemize}

\noindent
With these we can calculate:

\begin{equation}
\textrm{SE} = \textrm{Sensitivity} = \frac{a}{a + c}
\end{equation}

\begin{equation}
\textrm{SP} = \textrm{Specificity} = \frac{d}{b + d}
\end{equation}

Sensitivity and specificity can be calculated based on test
data alone. To calculate the sensitivity, we run the test on a
controlled environment where we allow only attack events to reach the
system. The ratio of reported attacks over all attacks will give us
the sensitivity. Similarly, to calculate the specificity we can run
the test on a controlled environment where we allow only innocuous
events to reach the system. The ratio of non-reported events over all
events will give us the specificity. 

\begin{table}[ht]

\caption{Attacks and Test Outcomes in Test Environment}
\label{tab:sensitivity-specificity}

\begin{tabular}{l|l|c|c|}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Attack} \\ \cline{3-4}
\multicolumn{2}{c|}{} & Yes & No \\ \cline{2-4}
\multirow{2}{*}{Result} &  Yes &  $a = \textrm{True Positive}$ & 
$b = \textrm{False Positive}$ \\
& No & $c = \textrm{False Negative}$ & $d = \textrm{True Negative}$ \\ 
\cline{2-4}
\multicolumn{2}{r|}{Total} & $a + c$ & $b + d$ \\
\cline{3-4}
\end{tabular}

\end{table}

Note that the calculations are carried out vertically in
Table~\ref{tab:sensitivity-specificity}; the ratio of attack events to
normal events does not enter into sensitivity and specificity. This is
what allows us to derive them based on test data, without using data
from a real production environment. At the same time, however, this is
what limits their usefulness. When we obtain a test result in a
production environment, be it negative or positive, we really want to
know how much we should be worried, or relaxed. In other words, if an
attack is detected in a production environment, how much should we be
worried? If no attack is detected in a production environment, how
relaxed should we be that no attack has indeed taken place?

\begin{table}[ht]

\caption{Attacks and Test Outcomes in Real Environment}
\label{tab:ppv-npv}

\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{Attack} & \\ \cline{3-4}
\multicolumn{2}{c|}{} & Yes & No & Total \\ \cline{2-5}
\multirow{2}{*}{Result} &  Yes &  $A = \textrm{True Positive}$ & 
$B = \textrm{False Positive}$ & \multicolumn{1}{c|}{$A + B$}\\
& No & $C = \textrm{False Negative}$ & $D = \textrm{True Negative}$ &
\multicolumn{1}{c|}{$C + D$}\\ 
\cline{2-5}
\end{tabular}

\end{table}

The answer to these questions is given by the \textsc{ppv} and the
\textsc{npv}. These depend not only on the test results, but also on
the \emph{prevalence} of attacks in real environments. In particular,
we can calculate them using Table~\ref{tab:ppv-npv}, which tabulates
results in a real environment, or in an environment where the
prevalence of attacks is equal to what we expect in the real world. To
indicate the difference with Table~\ref{tab:sensitivity-specificity}
we use capital letters for the entries in the table~\cite{linn2004}.
With this table, \textsc{ppv} and \textsc{npv} are given by the
following equations:

\begin{equation}
\textrm{PPV} = \frac{A}{A + C}
\end{equation}

\begin{equation}
\textrm{NPV} = \frac{D}{B + D}
\end{equation}

This time the ratios are taken horizontally; the ratio of attacks to
innocuous events affects the calculations. In fact, if PR is the
probability of attacks in the real world, the prevalence, then we
have~\cite{linn2004,altman1994}:

\begin{equation}
\textrm{PPV} = \frac{\textrm{SE}\times \textrm{PR}}{
\textrm{SE}\times \textrm{PR} + (1 - \textrm{SP})\times (1 -
\textrm{PR})}
\label{eq:ppv-se-sp}
\end{equation}

\begin{equation}
\textrm{NPV} = \frac{\textrm{SP}\times (1 - \textrm{PR})}{
(1 - \textrm{SE})\times \textrm{PR} + \textrm{SP}\times (1 -
\textrm{PR})}
\label{eq:npv-se-sp}
\end{equation}

The prevalence is the prior probability that an event is an attack,
based on our understanding of the volume and frequency of attacks; the
\textsc{ppv} and \textsc{npv} are the revised estimates of the
probability based on the results of the detection
mechanism~\cite{altman1994}. The lower the prevalence of an attack,
the more confident we can be that a negative test result indicates
that no attack has taken place and the less sure we can be that a
positive test result indicates a real attack. 

If published research does not include figures for Sensitivity and
Specificity or values for ($a$)--($d$), on test environments, then it
is not possible to judge the accuracy of the research at all. Even if
we do have such figures, a good research tool is not necessarily a
good practical tool. Even if a research tool scores well on
Sensitivity and Specificity, it may not be very useful in the real
world if the prevalence of the caught attacks is so low that a
positive test result is not likely to indicate a real attack.

To sum up, we evaluate diagnostic performance on two criteria:

\begin{itemize}
\item Reporting of Sensitivity and Specifity, either directly, or
  indirectly from published values of $a$--$d$.
\item Reporting of \textsc{ppv} and \textsc{npv}. This can be direct
  reporting of their values, or indirect from published values of
  $A$--$D$. Also, since from equations~\ref{eq:ppv-se-sp}
  and~\ref{eq:npv-se-sp} \textsc{ppv} and \textsc{npv} can be
  calculated by the sensitity and specifity given the prevalence, it
  can be via reporting prevalance, sensitivity, specificity.
\end{itemize}
 
\subsection{Computational Performance}

\subsection{Ease of Use}

\subsection{Security}

\subsection{Detection Locus}

\subsection{Availability}

\section{Defenses}
\label{sec:defs}

Figure~\ref{fig:defenses} presents a taxonomy of the
defenses that protect web applications against attacks based on
code injection vulnerabilities.
We can identify two main approaches, namely:
{\it design-based} and {\it behavior-based}.
The former involves mechanisms that make applications
immune to different attack vectors by design~\cite{JL75,L81}.
The latter incorporates a variety of methods and
schemes that inspect the behavior of applications
and detect attacks based on specific criteria~\cite{D76,A00}.
Both categories involve more than one subcategories.
For every subcategory we provide elements regarding
every dimension described in Section~\ref{sec:dimensions}.

Table~\ref{tab:comp} groups the various subcategories
and for every mechanism provides the following:

\begin{enumerate}
\item The number of citations of the publication(s) where
the mechanism was presented.
\item Quadruples that show the values of true
positives ({\sc tp}), true negatives ({\sc tn}),
false positives ({\sc fp}), and false negatives
({\sc tn}). For every quadruple there is a corresponding
suffix that indicates whether the testbed was based
on: real-world applications known to be vulnerable
(r), synthetic benchmarks (s), both (a).
If no testing has taken place we add a question
mark ({\bf ?}).
\item The computational overhead of the
mechanism as stated in the publication.
\item The attacks that the mechanism detects.
\end{enumerate}

\noindent
{\sc na} (Not Available) means that a requirement is not
mentioned in the paper. {\sc nq} (Not Quantified)
indicates that a requirement is mentioned in the publication
but it is not quantified.

Table~\ref{tab:avail} presents
our findings regarding the availability of the mechanism
in terms of source code and corresponding executables.
We also examined the availability of the testbeds mentioned in the paper.
The check mark (\tick) indicates that at some point within the publication,
there is a homepage where the reader can refer to, to download the
corresponding software. {\sc ao} (Available On-line) suggests that
the software is available on-line but the address was not mentioned
in the paper, which probably indicates that the authors made
it available after the publication. The question mark ({\bf ?}),
indicates that the a homepage for the software was included
in the publication but now it is not available.

Finally, as we mentioned in Subsection~\ref{sec:model},
Figure~\ref{fig:attacks} illustrates the point where
mechanisms detect attacks.

\subsection{Design-Based}
\label{sec:prot}

Here we analyze the {\sc tba} different protection approaches.
Note that most mechanisms that belong to this category have
not been extensively tested in terms of diagnostic performance.

\subsubsection{Parse-Tree Validation}

The mechanism based on this method compare the parse tree of a
query before the inclusion of user input with the one resulting after
the inclusion of user input. If the trees diverge, the application
is probably under attack.

\subsubsection{Securing Mashups}

\subsubsection{Code Rewriting}

\subsubsection{Instruction Set Randomization --- ISR}

{\sc isr} is a method that contrary to the previous
three, has been applied to counter
different kinds of application attacks~\cite{K09b,KKP03}.
The main idea behind the method, is to
separate code from data by randomizing the legitimate code's 
execution environment. In this way, the malicious code
injected by the attackers who do not know the randomization
algorithm, will not get executed.

{\it {\sc sql}rand}~\cite{BK04} is based on {\sc isr}
to detect {\sc sql} injections in the following manner:
initially, it allows programmers to create {\sc sql} statements
using randomized instructions instead of standard keywords.
The modified queries are either reconstructed at runtime using
the same key that is inaccessible to the malicious user,
or the user input is tagged with delimiters that allow
an augmented {\sc sql} grammar to detect the
attack. {\sc sql}rand is one of the few mechanisms that
detect {\sc sql} injection attacks on the database
level (locus $\Omega$).

In the case of {\sc xss} attacks that are based on JavaScript
or {\sc html}, consider a {\sc xor} function that encodes all source of a web
page on the server-side and then, on the client-side, the web browser decodes the
source by applying the same function again (locus {\sc x}).
Variations of this approach include:
{\it Noncespaces}~\cite{GC09} and {\it x{\sc js}}~\cite{APKLM10}
which randomize the instruction set of {\sc html} and
JavaScript respectively.

{\sc isr} is a deterministic approach that can be applied
to detect different attacks in an efficient manner.
However, Sovarel et al.~\cite{SEP05}
have investigated thoroughly the effectiveness
of {\sc isr} and showed that a malicious user
may be able to circumvent it by determining
the randomization key and their results
indicate that doing {\sc isr} in a way that
provides a certain degree of security against a motivated
attacker is more difficult than previously thought.

In the case of Noncespaces, administrators must set
specific policies in a manner similar to a firewall
configuration language. This brings up questions
concerning the diagnostic performance of the mechanism
since the corresponding testing is insufficient
(see Table~\ref{tab:comp}).

Even though the above implementations impose a low
computational overhead, they impose an infrastructure
overhead. In particular, in the case of {\sc sql}rand
the integration of a proxy within the database server
is required while Noncespaces and x{\sc js} require
modifications on both the server and the client.

\subsection{Behavior-Based}

\subsubsection{Runtime Tainting}

Runtime tainting is based on data-flow analysis.
In practice, it enforces security policies by marking untrusted
(``tainted") data and tracing its flow through the program.
Since information flow in a system cannot be verified by examining
a single execution trace of the system, the results of taint
analysis will necessarily reflect approximate information regarding
the information flow characteristics of the system to which it is applied.

\subsubsection{Policy Enforcement}

In this method, developers must define
specific security policies on the server side.
Then the policies are enforced either in the user's
browser at runtime or in a server-side proxy that
intercepts server responses.

\subsubsection{Training}

Training techniques are based on the ideas of Denning's original
intrusion detection framework~\cite{Den87}. In particular, a training
mechanism registers all valid legitimate code statements during a
training phase, most of the time in the form of signatures. This can
be done in various ways according to the implementation. Then, only
those will be accepted, approved or recognized during production.

Training methods that detect JavaScript-driven {\sc xss} attacks
generate and store valid JavaScript code in various
forms, and detect attacks as outliers from the set of valid code statements.
{\it {\sc swap}}~\cite{WPLKK09} encodes all the legitimate scripts that exist in the
original application. Then, a JavaScript detection component placed in a web proxy
searches for injected scripts in the server's responses. If no injected scripts
are found, the proxy decodes the legitimate scripts and sends them to the
client.
% dimitro: more mechanisms TBA.

In the case of {\sc dsl}-driven injection attacks
the various countermeasures follow a similar pattern.
An early approach, {\it {\sc didafit}}~\cite{LLW02} detects
{\sc sql} injection attacks by recording all database transactions.
Subsequent refinements by Valeur et al.~\cite{VMV05}
tagged each transaction with the corresponding application
as an extension of their anomaly detection framework called
{\it libAnomaly}\footnote[6]{\url{http://seclab.cs.ucsb.edu/academic/projects/projects/libanomaly/}}.
Furthermore, {\sc amnesia}~\cite{HO05,HO06} is a tool that also detects {\sc sql}
injection attacks by associating a query model with the location of every
{\sc sql} statement within the application. Then at runtime,
monitors the application's execution to detect when {\sc sql} statements
diverge from the expected model.
{\it {\sc sd}river}~\cite{MS09,MKS09} is a signature-based
mechanism that prevents
{\sc sql} and {\sc xp}ath injection attacks against web applications. 
The signatures generated during a training phase,
are based on features that can depend either on the
code statement or on its execution environment (i.e. the stack trace).
Then, at runtime, the mechanism checks all statements for compliance
and can block code statements containing injected elements.
By associating a complete stack trace with the root of an {\sc sql} statement, 
the mechanism can correlate {\sc sql} statements with their call sites.  
This increases the specificity of the stored signatures and 
avoids false alarms. 
% dimitro: more mechanisms TBA.

\begin{figure*}
\begin{center}
\leavevmode
\includegraphics[scale=0.52]{defenses.pdf}
\end{center}
\caption{\label{fig:defenses}The basic categories of web application
attack countermeasures ({\sc draft}).}
\end{figure*}

\begin{landscape}
\begin{table}
    \caption{Comparison summary of mechanisms developed to counter application attacks.}
    \label{tab:comp}
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|c|cc|c}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
	& \bf{\# of Citations}
  & \multicolumn{2}{|c|}{Requirements\tnote{1}}
	& \bf{Attack} \\
	&&& \bf{TP,TN,FP,FN}\tnote{2}
	& \bf{Computational Overhead} & \\
    \hline
  \multirow{2}{*}{Parse-Tree Validation}
  &   {\it {\sc sqlg}uard}~\cite{BWS05} & 243 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 3\% & {\sc sql} injection \\
  &   {\it {\sc sqlc}heck}~\cite{SW06} & 402 & (36848,7648,0,0)\_r & 3ms per query & {\sc sql} injection \\
  \hline
  \hline
  \multirow{5}{*}{Securing Mashups}
  &   {\it {\sc om}ash}~\cite{CHC08} & 58 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc nq} & {\sc csrf} \\
  &   {\it Mashup{\sc os}}~\cite{WFHJ07} & 149 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 1--59\% & {\sc xss} \\
  &   {\it ConScript}~\cite{ML10} & 122 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 7\% & {\sc xss} \\
  &   {\it WebJail}~\cite{VDDPJ11} & 25 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & $\sim$7ms & {\sc xss} \\
  &   {\it TreeHouse}~\cite{IW12} & 18 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & 757â€“-1218ms & {\sc xss} \\
  \hline
  \hline
  \multirow{3}{*}{{\sc isr}}
  &   {\it {\sc sql}rand}~\cite{BK04} & 286 & (3,{\sc na},{\sc na},0)\_a & +6.5{\it ms} & {\sc sql} injection \\ 
  &   {\it Noncespaces}~\cite{GC09} & 109 & ({\sc nq},{\sc na},{\sc na},0)\_r &  10.3\% & {\sc xss} \\ 
  &   {\it x{\sc js}}~\cite{APKLM10} & 18 & (1380,{\sc na},{\sc na},1)\_r & 1.6--40{\it ms} & {\sc xss} \\
  \hline
  \hline         
  \multirow{3}{*}{Code Rewriting}
  &   {\it BrowserShield}~\cite{RDWDE07} & 219 & (19,{\sc nq},0,0,)\_r & 8\% & {\sc xss} \\ 
  &   {\it CoreScript}~\cite{YCIS07} & 181 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_s & {\sc nq} & {\sc xss} \\
  &   {\it Phung et al.}~\cite{PSC09} & 75 & (37,{\sc na},{\sc na},4)\_r & 5.37\% & {\sc xss} \\
  \hline
  \hline
	\multirow{8}{*}{Runtime Tainting}
  &   {\it Haldar et al.}~\cite{HCF05} & 177 & (2,{\sc na},{\sc na},0)\_s & {\sc nq} & {\sc sql} injection, {\sc xss} \\ 
	&  	{\sc csse}~\cite{PB05} & 312 & (7,{\sc nq},{\sc nq},{\sc nq})\_r & 2--10\% & {\sc sql} injection, {\sc xp}ath, {\sc xss} \\
	% &  	{\it SecuriFly}~\cite{MLL05} & 31 & \xmark,\tick & 9--125\% & {\sc sql} injection, {\sc xss} \\ 
	&  	{\it Xu et al.}~\cite{XBS06} & 297 & (9,{\sc nq},0,{\sc nq})\_r & average 76\% & {\sc sql} injection, {\sc xss} \\ 
  &  	{\it {\sc wasc}}~\cite{NLC07} & 31 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & up to 30\% & {\sc sql} injection, {\sc xss} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07} & 322 & ({\sc nq},{\sc nq},{\sc nq},{\sc na})\_r & {\sc nq} & {\sc xss} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & 12 & (12,{\sc nq},{\sc nq},2)\_r & 2.2$\times$ & {\sc sql} and {\sc php} injection, {\sc xss} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & 0 & (1169,{\sc na},{\sc na},0)\_r & 7--17\% & {\sc dom}-based {\sc xss} \\
  &   {\it Diglossia}~\cite{SMS13} & 3 & (9,{\sc nq},{\sc nq},{\sc nq})\_r & 13\% & {\sc sql} and No{\sc sql} injection \\
  \hline
  \hline 
	\multirow{7}{*}{Policy Enforcement}
  &   {\it {\sc dsi}}~\cite{NSS06} & 135 & (5268,{\sc nq},46,15)\_r & 1.85\% & {\sc xss} \\ 
  &   {\it Noxes}~\cite{KKVJ06,KJKV09} & 268,40 & (3,{\sc na},{\sc na},0)\_r & {\sc na} & {\sc xss} \\
	&   {\it {\sc met}}~\cite{ELX07} & 58 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc xss} \\ 
  &   {\it {\sc beep}}~\cite{TNH07} & 282 & (61,{\sc na},{\sc na},0)\_r & 14.4\% & {\sc xss} \\
  &   {\it {\sc soma}}~\cite{OWVS08} & 46 & (5,{\sc na},{\sc na},0)\_s & 5.58\% & {\sc xss}, {\sc csrf}\\
	&   {\it Blueprint}~\cite{LV09} & 110 & (94,{\sc na},{\sc na},0)\_r & 13.6\% & {\sc xss} \\ 
	&   {\it j{\sc csrf}}~\cite{PS11} & 2 & (2,{\sc na},{\sc na},0)\_r & 2ms & {\sc csrf} \\
  % &   {\it {\sc js}and}~\cite{AVBPDP12} & 22 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & up to 31.2\% & {\sc xss}\\
  % TODO@dimitro: discuss this with Panos?
	\hline
	\hline  
  \multirow{9}{*}{Training}
  &   {\it {\sc didafit}}~\cite{LLW02} & 85 & ({\sc na},{\sc na},{\sc na},{\sc na})\_{\bf ?} & {\sc na} & {\sc sql} injection \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & 118,66,376 & (1470,{\sc nq},0,0)\_a & {\sc nq} & {\sc sql} injection \\ 
	&   {\it libAnomaly}~\cite{VMV05} & 226 & (344,15646,60,0)\_r & +1{\it ms} & {\sc sql} injection \\
	& 	{\it {\sc sm}ask}~\cite{JB07} & 27 & (5,{\sc nq},{\sc nq},{\sc nq})\_r  & {\sc na} & {\sc sql} injection, {\sc xss} \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & 64 & ({\sc nq},{\sc nq},{\sc nq},0)\_r & {\sc nq} &  {\sc xss} \\
  & 	{\it {\sc xss-guard}}~\cite{BV08} & 97 & (8,{\sc nq},{\sc nq},{\sc nq})\_r & 5--24\% & {\sc xss} \\
  & 	{\it {\sc swap}}~\cite{WPLKK09} & 52 & ({\sc nq},{\sc nq},{\sc nq},{\sc nq})\_r & $\sim$180\% & {\sc xss} \\ 
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & 21,8,5 & (241,{\sc nq},0,0)\_a & 39\% & {\sc sql} and {\sc xp}ath injection \\
	% & 	{\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} & 9,40,1 & \xmark,\xmark  & \xmark & {\sc sql} and {\sc xp}ath injection \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       	\item[1] {\sc na} (Not Available) means that a requirement is not mentioned in the paper.
	{\sc nq} (Not Quantified) indicates that a requirement is mentioned in the publication
	but it is not quantified.
		\item[2] For every quadruple there is a corresponding suffix that indicates whether the testbed was
	based on: a) real-world applications known to be vulnerable ({\it r}), b) synthetic benchmarks ({\it s}), c) both ({\it a}).
	If no testing has taken place we add a question mark ({\bf ?}).
	\end{footnotesize}
    \end{tablenotes}
    \end{small}
    \end{threeparttable}
\end{table}
\end{landscape}

\section{Analysis}

Notes on taint tools:
\begin{enumerate}
\item The accuracy testing of {\sc csse}~\cite{PB05} was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item During their evaluation, the authors of~\cite{HCF05} have only performed
two attacks in one synthetic benchmark ({\sc owasp}'s
{\it WebGoat}\footnote{\url{https://www.owasp.org/index.php/Category:OWASP_WebGoat_Project}}).
\item The testing in~\cite{XBS06} was made based on
defects with specific {\sc cve id}s.
\item The authors of {\it {\sc wasc}}~\cite{NLC07}
mention the vulnerabilities (specific {\sc cve id}s)
exploited and the corresponding applications but they do not explicitly
state how many attacks they launched (``{\it [...] launched a variety of
attacks against it}").
\item The authors of~\cite{VFJKKV07} do the same.
However, even if they do not mention specific {\sc cve id}s,
they browsed applications without performing attacks.
\item Even if the authors of {\it Noxes}~\cite{KKVJ06,KJKV09} state in
both papers that ``{\it [...] we are planning to make the tool available as
a freeware utility}." the tool cannot be found anywhere on the Internet.
The vulnerabilities exploited during testing were reported
by {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
\item {\it {\sc php} Aspis}~\cite{PMP11} was tested on only one
application (Wordpress 2.9.2) with multiple vulnerabilities (specific {\sc cve id}s).
\item During their initial tests, the authors of
managed to bypass the browser-based {\sc xss} filters of the
73\% of 1,602 real-world {\sc dom}-based {\sc xss} vulnerabilities.
Then they proposed an approach that detected all the attacks they
found (1169). This is a complex paper --- we need to elaborate.
\end{enumerate}

Notes on {\sc isr} mechanisms:
\begin{enumerate}
\item {\it {\sc sql}rand}~\cite{BK04}: Both exploits from {\sc cve} --- though
this is not mentioned in the publication.
\item {\it Noncespaces}~\cite{GC09} was only tested on one
known vulnerable application (TikiWiki). The authors mention that they performed
a number of attacks but they do not state how many.
\item The authors of {\it x{\sc js}}~\cite{APKLM10}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\end{enumerate}

Notes on policy enforcement tools:
\begin{enumerate}
\item Just like the authors of {\it x{\sc js}~\cite{APKLM10},
the authors of {\sc dsi}}~\cite{NSS06}, have tested
their mechanisms based on real-world attacks coming from
{\sc xss}ed.com.\footnote{www.xssed.com}
\item The testing of {\it BrowserShield}~\cite{RDWDE07}
involved {\sc xss} vulnerabilities reported by Microsoft
in 2005.\footnote{\url{https://technet.microsoft.com/en-us/security/bulletin}}
The link currently shows defects for 2014.
\item {\it CoreScript}~\cite{YCIS07} is more of a programming
language\footnote{``[...] uses program instrumentation for
JavaScript where untrusted JavaScript
code goes through a rewriting process according to a security policy
before executing them in the browser"~\cite{PSC09}.}
than an {\sc IDS}.
\item Surprisingly, {\sc met}~\cite{ELX07} was not tested at all.
\item {\sc beep}~\cite{TNH07}'s test suite was based on 61 {\sc xss}
attack vectors published by \url{ha.ckers.org}.
\item {\sc soma}~\cite{OWVS08} --- all synthetics.
\item The attacks used for the testing of {\it Blueprint}~\cite{LV09},
came from \url{ha.ckers.org}.
\item {\it Phung et al.}~\cite{PSC09} also utilized \url{ha.ckers.org}.
\item {\it WebJail}~\cite{VDDPJ11} --- not tested at all.
\item {\it ConScript}~\cite{ML10} --- not tested at all. A scheme
similar to {\it CoreScript}~\cite{YCIS07}.
\item {\it j{\sc csrf}}~\cite{PS11} --- based on {\sc csrf}
defects with specific {\sc cve id}s.
\item The authors of {\it TreeHouse}~\cite{IW12} have tested
only the overhead and how easy is to incorporate the mechanism
into an application.
\end{enumerate}

Notes on training-based mechanisms:
\begin{enumerate}
\item {\it {\sc didafit}}~\cite{LLW02} is one of
the first {\sc ids}.
\item {\sc amnesia}~\cite{HO05,HO06,HO05b} was tested
on applications with known vulnerabilities taken
from \url{http://gotocode.com} plus two synthetic benchmarks.
Interestingly, in one of the papers~\cite{HO06},
the authors mention that the tool can produce both {\sc fp} and
{\sc fn}.
\item {\it libAnomaly}~\cite{VMV05} --- one application tested ({\sc php}-Nuke).
\item {\sc sqlg}uard~\cite{BWS05} --- no testing at all.
\item {\sc sm}ask~\cite{JB07} was tested on real-world applications
with exploits from {\sc cve} --- though this is not mentioned in the publication.
\item {\sc xssds}~\cite{JEP08} --- testing was based on 
defects found in the security mailing
list: {\it Bugtraq}\footnote{\url{http://seclists.org/bugtraq/}}.
The authors provide multiple {\sc fp} rates depending on the experiment.
\item {\sc xss-guard}~\cite{BV08} was tested on real-world applications
with exploits from {\sc cve}.
\item {\sc swap}~\cite{WPLKK09} was tested on a real-world application ({\sc phpbb})
with exploits from {\sc cve} --- though this is not mentioned in the publication.
%\item {\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} have developed a
%mechanism to detect {\sc sql} and {\sc xp}ath injection attacks
%only on web services. Their testing involve a real-world benchmark
%({\sc tpc}-app).\footnote{\url{http://www.tpc.org/}}
\item {\it Diglossia}~\cite{SMS13} was tested on real-world applications
with exploits from {\sc cve}.
\end{enumerate}

\begin{table*}
\caption{Availability of the corresponding mechanisms.}
    \label{tab:avail}
\centering
    \begin{threeparttable}
    \begin{small}
\scalebox{0.99}{
    \begin{tabular}{l|c|ccc}
    \hline
    \bf{Approach}
	& \bf{Mechanism}
  & \multicolumn{3}{|c|}{Availability\tnote{1}} \\
	&& \bf{Source Code}
	& \bf{Executable}
	& \bf{Testbed} \\
    \hline
	\multirow{9}{*}{Runtime Tainting}
	&  	{\sc csse}~\cite{PB05} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Haldar et al.}~\cite{HCF05}  & {\sc na} & {\sc na} & {\sc na} \\
	% &  	{\it SecuriFly}~\cite{MLL05}  & - & - & - \\
	&  	{\it Xu et al.}~\cite{XBS06}  & {\sc na} & {\sc na} & {\sc na} \\
  &  	{\it {\sc wasc}}~\cite{NLC07} & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it Vogt et al.}~\cite{VFJKKV07}  & {\sc na} & {\sc na} & {\sc na} \\
	&  	{\it {\sc php} Aspis}~\cite{PMP11} & {\sc ao} & {\sc na} & {\sc ao} \\
	& 	{\it Stock et al.}~\cite{SLMS14} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Diglossia}~\cite{SMS13} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline      
	\multirow{3}{*}{{\sc isr}}
	&   {\it {\sc sql}rand}~\cite{BK04} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it Noncespaces}~\cite{GC09} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it x{\sc js}}~\cite{APKLM10} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline
  \multirow{2}{*}{Parse-Tree Validation}
  &   {\it {\sc sqlc}heck}~\cite{SW06} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it {\sc sqlg}uard}~\cite{BWS05} & {\sc ao} & {\sc ao} & {\sc na} \\
  \hline  
  \hline 
  \hline
  \multirow{3}{*}{Code Rewriting}
  &   {\it BrowserShield}~\cite{RDWDE07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it CoreScript}~\cite{YCIS07} & {\sc ao} & {\sc na} & {\sc na} \\
  &   {\it Phung et al.}~\cite{PSC09} & \tick & \tick & \tick \\
  \hline
  \hline 
  \multirow{5}{*}{Securing Mashups}
  &   {\it {\sc om}ash}~\cite{CHC08} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Mashup{\sc os}}~\cite{WFHJ07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it ConScript}~\cite{ML10} & {\sc ao} & {\sc na} & {\sc na} \\
  &   {\it WebJail}~\cite{VDDPJ11} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it TreeHouse}~\cite{IW12} & {\sc na} & {\sc na} & {\sc na} \\
  \hline
  \hline
	\multirow{7}{*}{Policy Enforcement}
	&   {\it {\sc dsi}}~\cite{NSS06} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it Noxes}~\cite{KKVJ06,KJKV09}  & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it {\sc met}}~\cite{ELX07} & {\sc na} & {\sc na} & {\sc na} \\
  &   {\it {\sc beep}}~\cite{TNH07} & \tick & \tick & \tick \\
  &   {\it {\sc soma}}~\cite{OWVS08} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it Blueprint}~\cite{LV09} & {\bf ?} & {\bf ?} & {\bf ?} \\
	&   {\it j{\sc csrf}}~\cite{PS11} & {\sc na} & {\sc na} & {\sc na} \\
   	% &   {\it {\sc js}and}~\cite{AVBPDP12} & {\sc na} & {\sc na} & {\sc na} \\
	\hline
	\hline  
        \multirow{9}{*}{Training}
  &   {\it {\sc didafit}}~\cite{LLW02} & {\sc na} & {\sc na} & {\sc na} \\
	&   {\it {\sc amnesia}}~\cite{HO05,HO06,HO05b} & {\sc na} & {\sc ao} & {\sc na} \\
	&   {\it libAnomaly}~\cite{VMV05} & {\bf ?} & {\bf ?} & {\bf ?} \\
	& 	{\it {\sc sm}ask}~\cite{JB07} & {\sc na} & {\sc na} & {\sc na} \\
	& 	{\it {\sc xssds}}~\cite{JEP08} & {\sc na} & {\sc na} & {\sc na} \\
  & 	{\it {\sc xss-guard}}~\cite{BV08} & {\sc na} & {\sc na} & {\sc na} \\
  & 	{\it {\sc swap}}~\cite{WPLKK09} & {\sc na} & {\sc na} & {\sc na} \\
	& 	{\it {\sc sd}river}~\cite{MS09,MKS09,MKLS11} & \tick & \tick & {\sc na} \\
	% & 	{\it Laranjeiro et al.}~\cite{LVM09,ALVM09,LVM10} & {\bf ?} & {\bf ?} & {\bf ?} \\
	\hline
    \end{tabular}}
    \begin{tablenotes}
	\begin{footnotesize}
       \item[1] The check mark (\tick) indicates that the publication
       includes a homepage where the reader can refer to, to
       download the corresponding software. {\sc ao} (Available On-line) suggests
       that the software is available on-line but the
       address was not mentioned in the paper, which probably indicates that
       the authors made it available after the publication. The question ({\bf ?})
       mark, indicates that the a homepage for the software was included
       in the publication but now it is not available.
	\end{footnotesize}
    \end{tablenotes}
    \end{small}
    \end{threeparttable}
\end{table*}

\section{Conclusions}

% Cite~\cite{HNSHS12}.

\bibliographystyle{IEEEtran}
\bibliography{questioning}

\end{document} 

